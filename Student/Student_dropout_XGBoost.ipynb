{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#import ydata_profiling\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "1LBgZtCayAzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploades = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "XQG9kFT7zQnQ",
        "outputId": "dc128867-287a-47fa-c7b8-eb6c8799cd64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0d3f9b1-9fc5-43e6-851a-318ae1f3b9f1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d0d3f9b1-9fc5-43e6-851a-318ae1f3b9f1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dataset.csv')"
      ],
      "metadata": {
        "id": "WGWWpxfOzSfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "# Using .fit_transform function to fit label\n",
        "# encoder and return encoded label\n",
        "label = le.fit_transform(df['Target'])\n",
        "# removing the column 'Purchased' from df\n",
        "# as it is of no use now.\n",
        "df.drop(\"Target\", axis=1, inplace=True)\n",
        "\n",
        "# Appending the array to our dataFrame\n",
        "# with column name 'Purchased'\n",
        "df[\"Target\"] = label\n",
        "\n",
        "# printing Dataframe\n",
        "df.tail(5)\n",
        "df['Target'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoXHmEBm9LDt",
        "outputId": "7d18b74e-da23-4cd6-d030-7c046dc27596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "11jfxKEjVMFX",
        "outputId": "8656652b-0621-4893-add6-ff91cafea1a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Marital status  Application mode  Application order  Course  \\\n",
              "0               1                 8                  5       2   \n",
              "1               1                 6                  1      11   \n",
              "2               1                 1                  5       5   \n",
              "3               1                 8                  2      15   \n",
              "4               2                12                  1       3   \n",
              "\n",
              "   Daytime/evening attendance  Previous qualification  Nacionality  \\\n",
              "0                           1                       1            1   \n",
              "1                           1                       1            1   \n",
              "2                           1                       1            1   \n",
              "3                           1                       1            1   \n",
              "4                           0                       1            1   \n",
              "\n",
              "   Mother's qualification  Father's qualification  Mother's occupation  ...  \\\n",
              "0                      13                      10                    6  ...   \n",
              "1                       1                       3                    4  ...   \n",
              "2                      22                      27                   10  ...   \n",
              "3                      23                      27                    6  ...   \n",
              "4                      22                      28                   10  ...   \n",
              "\n",
              "   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
              "0                                    0                                    0   \n",
              "1                                    0                                    6   \n",
              "2                                    0                                    6   \n",
              "3                                    0                                    6   \n",
              "4                                    0                                    6   \n",
              "\n",
              "   Curricular units 2nd sem (evaluations)  \\\n",
              "0                                       0   \n",
              "1                                       6   \n",
              "2                                       0   \n",
              "3                                      10   \n",
              "4                                       6   \n",
              "\n",
              "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "0                                    0                          0.000000   \n",
              "1                                    6                         13.666667   \n",
              "2                                    0                          0.000000   \n",
              "3                                    5                         12.400000   \n",
              "4                                    6                         13.000000   \n",
              "\n",
              "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "0                                               0               10.8   \n",
              "1                                               0               13.9   \n",
              "2                                               0               10.8   \n",
              "3                                               0                9.4   \n",
              "4                                               0               13.9   \n",
              "\n",
              "   Inflation rate   GDP  Target  \n",
              "0             1.4  1.74       0  \n",
              "1            -0.3  0.79       2  \n",
              "2             1.4  1.74       0  \n",
              "3            -0.8 -3.12       2  \n",
              "4            -0.3  0.79       2  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa91cbae-75fd-4370-b90c-dceaf2833409\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Nacionality</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>Mother's occupation</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 2nd sem (credited)</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>27</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-3.12</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>28</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa91cbae-75fd-4370-b90c-dceaf2833409')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa91cbae-75fd-4370-b90c-dceaf2833409 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa91cbae-75fd-4370-b90c-dceaf2833409');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_top = df.head()\n",
        "# for col in df.columns:\n",
        "#   print(df[col].unique())"
      ],
      "metadata": {
        "id": "KxDXuKBLVJ4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ea6Kbi8XYp3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Target'],axis=1)\n",
        "y = df['Target']"
      ],
      "metadata": {
        "id": "608EVdQR9QYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3 ,random_state=42)"
      ],
      "metadata": {
        "id": "D0q9KvfCzeuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [  {'learning_rate': [0.01,0.001,0.1,0.2,0.02], 'max_depth':range(0,10,1),\n",
        "                 }]"
      ],
      "metadata": {
        "id": "3E4MlRv7zfe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "display(IPython.display.Javascript('''\n",
        "function ClickConnect()\n",
        "  btn == document. querySelector(\"colab-connect-button\")\n",
        "  if (btn ! = null) {\n",
        "    console. log(\"Click colab-connect-button\");\n",
        "    btn.click()\n",
        "    }\n",
        "  btn = document.getElementById(ok')\n",
        "  if (btn != null) {\n",
        "    console. .log(\"Click reconnect\");\n",
        "    btn.click()\n",
        "                               I\n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bosnTv3n2NRz",
        "outputId": "a03f039e-1f18-41c4-fa5b-4143844c5d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "function ClickConnect()\n",
              "  btn == document. querySelector(\"colab-connect-button\")\n",
              "  if (btn ! = null) {\n",
              "    console. log(\"Click colab-connect-button\");\n",
              "    btn.click()\n",
              "    }\n",
              "  btn = document.getElementById(ok')\n",
              "  if (btn != null) {\n",
              "    console. .log(\"Click reconnect\");\n",
              "    btn.click()\n",
              "                               I\n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=10)\n",
        "# from lightgbm import LightGBMClassifier\n",
        "xgb = xgboost.XGBClassifier()\n",
        "grid_search = GridSearchCV(xgb, param_grid, cv=cv, return_train_score=True, n_jobs = -1)"
      ],
      "metadata": {
        "id": "ifT-xSG62WkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9Byh0ai978E",
        "outputId": "f14ee5d2-d4a3-43ac-f41f-1a20636bd41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.2, 'max_depth': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "v9sWBsLPI0yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [  {'learning_rate': [0.2], 'max_depth':[4],'max_leaves' : range(10,50),\n",
        "                 }]\n",
        "# from lightgbm import LightGBMClassifier\n",
        "xgb = xgboost.XGBClassifier()\n",
        "grid_search = GridSearchCV(xgb, param_grid, cv=cv, return_train_score=True, n_jobs = -1)"
      ],
      "metadata": {
        "id": "n_l_lf03JP1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmMQvJsUJWJN",
        "outputId": "ea3db6c5-fbaa-41e8-dad2-7a40e57de8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.2, 'max_depth': 4, 'max_leaves': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [  {'learning_rate': [0.2], 'max_depth':[4],'max_leaves' : [10],'min_child_weight':range(0,10,1),\n",
        "                 }]\n",
        "# from lightgbm import LightGBMClassifier\n",
        "xgb = xgboost.XGBClassifier()\n",
        "grid_search = GridSearchCV(xgb, param_grid, cv=cv, return_train_score=True, n_jobs = -1)"
      ],
      "metadata": {
        "id": "01_dgJjXsWSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sll0hoi_JWad",
        "outputId": "e619ba9f-6b2e-4c1c-a7f3-738aab0b630a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.2, 'max_depth': 4, 'max_leaves': 10, 'min_child_weight': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [  {'learning_rate': [0.2], 'max_depth':[4],'max_leaves' : [10],'min_child_weight':[2],'subsample':[0.8,0.9,1],\n",
        "                 }]\n",
        "# from lightgbm import LightGBMClassifier\n",
        "xgb = xgboost.XGBClassifier()\n",
        "grid_search = GridSearchCV(xgb, param_grid, cv=cv, return_train_score=True, n_jobs = -1)"
      ],
      "metadata": {
        "id": "0aBPZHNHJWeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PhCIcnDJWiL",
        "outputId": "dc5f6e8c-a6c9-4a80-e60a-9e59b6fc36b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.2,\n",
              " 'max_depth': 4,\n",
              " 'max_leaves': 10,\n",
              " 'min_child_weight': 2,\n",
              " 'subsample': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [  {'learning_rate': [0.2], 'max_depth':[4],'max_leaves' : [10],'min_child_weight':[2],'subsample':[1],\n",
        "                 'colsample_bytree':[0.8,0.9,1],'gamma':[0,0.01,0.02],\n",
        "                 }]\n",
        "# from lightgbm import LightGBMClassifier\n",
        "xgb = xgboost.XGBClassifier()\n",
        "grid_search = GridSearchCV(xgb, param_grid, cv=cv, return_train_score=True, n_jobs = -1)"
      ],
      "metadata": {
        "id": "telYuCP0JWrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SxzXBaIxFqn",
        "outputId": "20b8ca26-72f9-48e9-ac87-0a172bc09c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.8,\n",
              " 'gamma': 0.01,\n",
              " 'learning_rate': 0.2,\n",
              " 'max_depth': 4,\n",
              " 'max_leaves': 10,\n",
              " 'min_child_weight': 2,\n",
              " 'subsample': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta7knMFXywYR",
        "outputId": "012153f2-eba0-4f61-bac4-a177dca58fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7794893428526761"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgb = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "CNkDc_01ywcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgb.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "aPgP29EXywfz",
        "outputId": "95a5b626-c3b8-4ba0-f814-88bf8e2ab96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.01, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=10,\n",
              "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              objective='multi:softprob', predictor=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.01, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=10,\n",
              "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=0.01, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=10,\n",
              "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = best_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "tvH1XUFzy7cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import accuracy_score, precision_score, classification_report,f1_score, recall_score, confusion_matrix\n",
        "accuracy = accuracy_score(y_test, pred_y)\n",
        "print(accuracy)\n",
        "recall = recall_score(y_test, pred_y,average='macro')\n",
        "print(recall)\n",
        "precision = precision_score(y_test, pred_y,average='macro')\n",
        "print(precision)\n",
        "f1 = f1_score(y_test, pred_y,average='macro')\n",
        "print(f1)\n",
        "print('Classification report for XGB Model:\\n',classification_report(y_test, pred_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sPeKZbey7gw",
        "outputId": "faddb658-8c91-4dae-d120-57d21b2191d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7725903614457831\n",
            "0.6944115964142666\n",
            "0.7251570063514131\n",
            "0.7029485076039629\n",
            "Classification report for XGB Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.78      0.79       441\n",
            "           1       0.57      0.39      0.46       245\n",
            "           2       0.80      0.92      0.85       642\n",
            "\n",
            "    accuracy                           0.77      1328\n",
            "   macro avg       0.73      0.69      0.70      1328\n",
            "weighted avg       0.76      0.77      0.76      1328\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, pred_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBLtgcmhzDEu",
        "outputId": "3893eaea-6e40-4646-b401-8061d232cbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[342  44  55]\n",
            " [ 56  96  93]\n",
            " [ 25  29 588]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grid_search = GridSearchCV(xgb, param_grid, cv = 5, return_train_score = True, n_jobs = -1)"
      ],
      "metadata": {
        "id": "rtWKRHvI2f3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HpW7IzdxJN_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZL3Y6Gn2914",
        "outputId": "271a220f-9a73-4689-cf3b-6c75ce16145f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=XGBClassifier(), n_jobs=-1,\n",
              "             param_grid=[{'colsample_bytree': [0.4, 0.5, 0.7],\n",
              "                          'gamma': [0.0, 0.1, 0.2],\n",
              "                          'learning_rate': [0.2, 0.3, 0.4],\n",
              "                          'max_depth': [5, 6, 7],\n",
              "                          'min_child_weight': [0, 1, 2, 3]}],\n",
              "             return_train_score=True)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grid_search.cv_results_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYLznqYl8WP6",
        "outputId": "5e283344-c19d-4d9d-9132-e1752776dc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([1.41639228, 1.38559093, 0.96245122, 0.93454881, 1.20030146,\n",
              "        1.53229012, 1.18627753, 1.12951522, 1.58957815, 1.90805469,\n",
              "        1.36075511, 1.33411865, 1.41658893, 0.95781641, 0.95848041,\n",
              "        0.93043842, 1.66171045, 1.14304519, 1.25001578, 1.62059059,\n",
              "        1.75798073, 1.38165693, 1.5052299 , 1.5842452 , 1.07295032,\n",
              "        0.94889755, 1.0872963 , 1.24520731, 1.21979856, 1.14204946,\n",
              "        1.34285727, 1.31728325, 1.48973579, 1.34714437, 1.76309681,\n",
              "        1.33236847, 0.98926058, 1.19095421, 1.1968071 , 0.95232787,\n",
              "        1.1994348 , 1.39915266, 1.33065038, 1.12843981, 1.5346252 ,\n",
              "        1.79433899, 1.35053821, 1.33980784, 1.33878489, 1.01697416,\n",
              "        0.93881121, 0.93328414, 1.47639623, 1.3538281 , 1.14469461,\n",
              "        1.12101498, 1.95457864, 1.35652642, 1.3421659 , 1.7667788 ,\n",
              "        0.98235922, 0.96372247, 0.95411172, 1.05573802, 1.51259665,\n",
              "        1.16931477, 1.13756776, 1.53216271, 1.49291787, 1.33499808,\n",
              "        1.64818501, 1.46681271, 0.97727218, 0.95728812, 1.25195146,\n",
              "        1.09603653, 1.20391722, 1.16277437, 1.46725698, 1.26488981,\n",
              "        1.46881394, 1.52616277, 1.6531827 , 1.35312352, 0.9743526 ,\n",
              "        1.40038667, 0.9353003 , 0.9441155 , 1.20735383, 1.60652838,\n",
              "        1.13540158, 1.11975784, 1.51038108, 1.73168921, 1.32735581,\n",
              "        1.30001979, 1.32191892, 1.03681526, 0.91860161, 0.92155976,\n",
              "        1.33023601, 1.44064841, 1.12548919, 1.10270443, 1.80086169,\n",
              "        1.4444706 , 1.32067952, 1.52220893, 1.36400933, 1.0948473 ,\n",
              "        1.07365942, 1.37196016, 1.64246435, 1.35210366, 1.41871862,\n",
              "        1.63466768, 1.75049372, 1.94435744, 1.6439949 , 1.54158611,\n",
              "        1.44172807, 1.26581044, 1.07445607, 1.05768709, 1.83958964,\n",
              "        1.36999359, 1.33030334, 1.56675253, 1.94969068, 1.60491118,\n",
              "        2.00270634, 1.52839608, 1.13230696, 1.37442403, 1.21663337,\n",
              "        1.07197404, 1.41949096, 1.8044189 , 1.33456726, 1.30255709,\n",
              "        2.22989898, 1.56976089, 1.53934946, 1.92670221, 1.13527732,\n",
              "        1.08730536, 1.23090076, 1.41265817, 1.42985344, 1.35335875,\n",
              "        1.74978504, 1.31175542, 1.75192809, 2.05758104, 1.57486033,\n",
              "        1.61997547, 1.48722858, 1.08312383, 1.08554101, 1.20583081,\n",
              "        1.71952477, 1.33711505, 1.34903016, 1.70081701, 1.71529584,\n",
              "        1.66494141, 1.91523123, 1.54321594, 1.24032831, 1.44489822,\n",
              "        1.07439117, 1.07421494, 1.64973278, 1.50804434, 1.2967    ,\n",
              "        1.33162513, 2.15450282, 1.57354722, 1.83768535, 1.63015199,\n",
              "        1.13059716, 1.09974842, 1.54338446, 1.07907372, 1.38608527,\n",
              "        1.81799369, 1.3182826 , 1.300948  , 2.03110294, 1.76504788,\n",
              "        1.60862122, 2.02821169, 1.12677073, 1.09659534, 1.11716819,\n",
              "        1.45746593, 1.37806487, 1.32844253, 1.78004122, 1.30951343,\n",
              "        1.67918863, 2.03567657, 1.52671285, 1.51525979, 1.50114551,\n",
              "        1.13143368, 1.06873193, 1.07036586, 1.83403845, 1.3249217 ,\n",
              "        1.30522141, 1.7169507 , 1.67646551, 1.57214618, 2.01632199,\n",
              "        1.50858326, 1.31775346, 1.73094749, 1.28196316, 1.27676525,\n",
              "        2.04719005, 1.72289824, 1.58503952, 2.02897515, 2.12398672,\n",
              "        2.43559065, 1.92543831, 1.9611733 , 1.73363018, 1.30772429,\n",
              "        1.27285595, 1.71258912, 1.67951727, 1.60716267, 2.01516371,\n",
              "        1.56755633, 2.43510017, 2.05662084, 2.0884654 , 2.13905573,\n",
              "        1.35128393, 1.49674306, 1.56186128, 1.2650423 , 1.8979486 ,\n",
              "        1.85613513, 1.58161469, 1.94787354, 2.19860101, 1.95166802,\n",
              "        2.24724689, 1.84231782, 1.76110764, 1.34399343, 1.30538406,\n",
              "        1.43566346, 1.96811666, 1.59274945, 1.98809538, 1.62595859,\n",
              "        2.19124374, 2.30787039, 1.90352802, 2.34208927, 1.34329977,\n",
              "        1.32221508, 1.71878872, 1.2768568 , 1.67927599, 2.07881989,\n",
              "        1.5848805 , 1.54268866, 2.60603766, 1.94123726, 2.33978076,\n",
              "        1.85183244, 1.45126061, 1.66912761, 1.32345552, 1.35405879,\n",
              "        2.20768933, 1.60754485, 1.77084665, 1.81053658, 2.06093788,\n",
              "        2.33707204, 1.85056648, 2.25308208, 1.35063276, 1.31853395,\n",
              "        1.4864069 , 1.57300177, 1.68535433, 1.91991029, 1.76912379,\n",
              "        1.56672473, 2.5644732 , 1.95586696, 2.21266403, 1.99088326,\n",
              "        1.31880341, 1.76607256, 1.27747459, 1.26967816, 1.96901412,\n",
              "        1.77345023, 1.57825804, 1.98054857, 2.03098989, 2.05245476,\n",
              "        2.15120463, 1.81643772, 1.7941433 , 1.29276056, 1.2950253 ,\n",
              "        1.49585419, 1.88830414, 1.58296952, 1.95099006, 1.58884926,\n",
              "        2.02680984, 2.27250028, 1.83675079, 2.26687965]),\n",
              " 'std_fit_time': array([0.51489018, 0.32802166, 0.02375513, 0.01591037, 0.00970659,\n",
              "        0.42865074, 0.05423767, 0.00897668, 0.19498401, 0.0672631 ,\n",
              "        0.01636403, 0.01116557, 0.25189039, 0.01504829, 0.01138389,\n",
              "        0.00709901, 0.49376058, 0.00922053, 0.14951472, 0.62366356,\n",
              "        0.30570889, 0.03105995, 0.32825702, 0.34674833, 0.11016803,\n",
              "        0.01340011, 0.29610978, 0.32906547, 0.01652307, 0.00727195,\n",
              "        0.38149821, 0.40545744, 0.01099327, 0.00682083, 0.40608923,\n",
              "        0.02106094, 0.01292363, 0.28848067, 0.26726622, 0.00647086,\n",
              "        0.0127603 , 0.28597996, 0.2386445 , 0.01650514, 0.02247992,\n",
              "        0.49517018, 0.01061908, 0.01178318, 0.32406207, 0.11701279,\n",
              "        0.00598302, 0.00739934, 0.42313563, 0.39141882, 0.02141764,\n",
              "        0.0121256 , 0.54162182, 0.006593  , 0.01988752, 0.38028235,\n",
              "        0.00763766, 0.0108333 , 0.01597288, 0.21822869, 0.39547736,\n",
              "        0.01542483, 0.01149835, 0.39852295, 0.0607936 , 0.00800775,\n",
              "        0.3893663 , 0.32439931, 0.00883468, 0.00677792, 0.31773608,\n",
              "        0.29882572, 0.01382346, 0.0168896 , 0.27808182, 0.24222258,\n",
              "        0.02578674, 0.19404015, 0.36564057, 0.00996909, 0.01489221,\n",
              "        0.25556021, 0.01044189, 0.02463525, 0.01213019, 0.42172406,\n",
              "        0.00541575, 0.00491026, 0.1476382 , 0.31999955, 0.02147914,\n",
              "        0.01675512, 0.23927187, 0.19293743, 0.00888011, 0.01109577,\n",
              "        0.26082924, 0.30584666, 0.00825926, 0.01894277, 0.31723536,\n",
              "        0.14329982, 0.01636155, 0.27253135, 0.27140044, 0.01064611,\n",
              "        0.0118582 , 0.3092504 , 0.29257662, 0.03561798, 0.19864845,\n",
              "        0.31044076, 0.0148539 , 0.43357238, 0.10064706, 0.01630742,\n",
              "        0.4047725 , 0.28052202, 0.01351674, 0.00361951, 0.45076393,\n",
              "        0.01710202, 0.01249332, 0.34041323, 0.21487532, 0.01367317,\n",
              "        0.54849109, 0.00603574, 0.01431883, 0.35381233, 0.19476894,\n",
              "        0.01394297, 0.01350058, 0.31842405, 0.02450908, 0.02528449,\n",
              "        0.56979054, 0.01626568, 0.03701476, 0.50461714, 0.02522709,\n",
              "        0.01583058, 0.23300486, 0.35137578, 0.00995751, 0.01690049,\n",
              "        0.28409621, 0.00863209, 0.02733278, 0.52180151, 0.01123172,\n",
              "        0.08541256, 0.44371369, 0.01243177, 0.00825578, 0.16363297,\n",
              "        0.40506957, 0.00944022, 0.03885343, 0.40316168, 0.01278305,\n",
              "        0.13318192, 0.41923812, 0.01433491, 0.21948536, 0.28469395,\n",
              "        0.00834558, 0.02317792, 0.34479188, 0.38532018, 0.01871039,\n",
              "        0.03530164, 0.52727529, 0.0320602 , 0.28729752, 0.24506288,\n",
              "        0.00410044, 0.00979406, 0.34260273, 0.0145806 , 0.01046883,\n",
              "        0.53363237, 0.01107076, 0.01622319, 0.31002157, 0.25955822,\n",
              "        0.03824812, 0.37952262, 0.02352153, 0.01903179, 0.08841515,\n",
              "        0.37154039, 0.01127247, 0.00814301, 0.50106   , 0.01783891,\n",
              "        0.01710315, 0.24726648, 0.01303009, 0.01498857, 0.32553567,\n",
              "        0.0686528 , 0.02181848, 0.0057147 , 0.43262617, 0.01419231,\n",
              "        0.01283951, 0.52326   , 0.02631247, 0.01296786, 0.5028074 ,\n",
              "        0.01547818, 0.01403838, 0.32327886, 0.01493102, 0.00595319,\n",
              "        0.36986079, 0.210249  , 0.03384299, 0.28163179, 0.02617892,\n",
              "        0.59398158, 0.04507443, 0.16249079, 0.4140784 , 0.02941748,\n",
              "        0.00714877, 0.33122555, 0.01008385, 0.02745455, 0.34271994,\n",
              "        0.01909764, 0.33429078, 0.28096845, 0.33580917, 0.31110458,\n",
              "        0.01436462, 0.27094572, 0.33667364, 0.005872  , 0.4009287 ,\n",
              "        0.25965493, 0.01408536, 0.49643066, 0.06234733, 0.13664494,\n",
              "        0.44837666, 0.0072473 , 0.35111914, 0.09506811, 0.03158549,\n",
              "        0.21680709, 0.37518349, 0.01397472, 0.40117841, 0.08704189,\n",
              "        0.23286404, 0.35286292, 0.01437266, 0.4502459 , 0.00435735,\n",
              "        0.0076561 , 0.37291159, 0.01701821, 0.02005591, 0.27956585,\n",
              "        0.0237836 , 0.02240123, 0.56021947, 0.02726912, 0.49618478,\n",
              "        0.0096085 , 0.20657562, 0.27604998, 0.03921943, 0.00962574,\n",
              "        0.26580452, 0.01414964, 0.41804506, 0.28712132, 0.02698692,\n",
              "        0.41931759, 0.01362625, 0.54564971, 0.01873562, 0.00915816,\n",
              "        0.35715396, 0.32965989, 0.01679245, 0.35446519, 0.20196007,\n",
              "        0.02248842, 0.57748688, 0.00959816, 0.35063319, 0.26749554,\n",
              "        0.01001075, 0.34055004, 0.01068737, 0.01043068, 0.40252893,\n",
              "        0.36444565, 0.02130405, 0.39669462, 0.02673597, 0.25133773,\n",
              "        0.30541069, 0.01366874, 0.47854499, 0.0139346 , 0.01986114,\n",
              "        0.30221233, 0.29684062, 0.02571065, 0.34315437, 0.12434285,\n",
              "        0.03698456, 0.40252552, 0.02618192, 0.41883832]),\n",
              " 'mean_score_time': array([0.01728535, 0.02684469, 0.01764746, 0.01688118, 0.01959991,\n",
              "        0.03057714, 0.01953087, 0.02022276, 0.02750664, 0.02230792,\n",
              "        0.02192974, 0.02149496, 0.02324576, 0.01707621, 0.01838336,\n",
              "        0.01755924, 0.03197408, 0.02112656, 0.01975369, 0.03503799,\n",
              "        0.0232646 , 0.02153087, 0.02550611, 0.02584209, 0.01710873,\n",
              "        0.01638069, 0.01695814, 0.01971564, 0.01938763, 0.01912599,\n",
              "        0.02503076, 0.02236753, 0.02316008, 0.02281518, 0.02806478,\n",
              "        0.0222899 , 0.01848559, 0.02327356, 0.01729355, 0.01681967,\n",
              "        0.01938171, 0.02813392, 0.01960368, 0.01937318, 0.02869692,\n",
              "        0.026755  , 0.02227221, 0.02145376, 0.02929988, 0.01714849,\n",
              "        0.01656761, 0.01671419, 0.02799301, 0.0195859 , 0.01908283,\n",
              "        0.01950431, 0.02255869, 0.02281203, 0.02135119, 0.03071856,\n",
              "        0.01672897, 0.01695542, 0.01673055, 0.02280755, 0.02341619,\n",
              "        0.01928239, 0.01969104, 0.02325239, 0.02092481, 0.02135701,\n",
              "        0.02644773, 0.02124538, 0.01656852, 0.01720181, 0.02558713,\n",
              "        0.01848741, 0.01926665, 0.01932621, 0.02695436, 0.02024455,\n",
              "        0.02169633, 0.03176827, 0.02288895, 0.02176204, 0.01788001,\n",
              "        0.02208714, 0.01647377, 0.01828008, 0.01881971, 0.02698903,\n",
              "        0.01894135, 0.01898427, 0.02412639, 0.02063713, 0.02061677,\n",
              "        0.02101221, 0.02913299, 0.01647429, 0.01796465, 0.01660876,\n",
              "        0.02363381, 0.02095294, 0.01871705, 0.02077284, 0.02162347,\n",
              "        0.01978998, 0.01962075, 0.02774677, 0.01719146, 0.01648798,\n",
              "        0.01675987, 0.0287241 , 0.02032557, 0.01965013, 0.02263489,\n",
              "        0.02365627, 0.02884488, 0.03172512, 0.02258959, 0.0214839 ,\n",
              "        0.02571211, 0.01718559, 0.01690593, 0.01653352, 0.02916751,\n",
              "        0.02025137, 0.01941299, 0.023843  , 0.02285466, 0.02306242,\n",
              "        0.02553329, 0.02094922, 0.01795788, 0.02078514, 0.01654153,\n",
              "        0.016501  , 0.01955528, 0.02457995, 0.02007403, 0.01978765,\n",
              "        0.02652626, 0.02365885, 0.02253823, 0.02509475, 0.01650429,\n",
              "        0.01643176, 0.02039781, 0.021591  , 0.0194397 , 0.0195631 ,\n",
              "        0.02744455, 0.01927571, 0.02618213, 0.0234477 , 0.02180729,\n",
              "        0.02920375, 0.02093148, 0.01627765, 0.01920514, 0.02271547,\n",
              "        0.01944747, 0.01911659, 0.02373161, 0.02393346, 0.02081842,\n",
              "        0.02697067, 0.0210207 , 0.0213963 , 0.01936588, 0.01924858,\n",
              "        0.01651306, 0.01731143, 0.02486796, 0.01886697, 0.02058878,\n",
              "        0.023137  , 0.02010159, 0.02048888, 0.02861891, 0.02156239,\n",
              "        0.01661983, 0.017976  , 0.02492633, 0.01685176, 0.01907105,\n",
              "        0.02252512, 0.01918087, 0.01893406, 0.02918892, 0.02228169,\n",
              "        0.0214057 , 0.02790489, 0.01669021, 0.01662951, 0.01960206,\n",
              "        0.01923456, 0.01910691, 0.01896639, 0.02687354, 0.01861753,\n",
              "        0.01958599, 0.02291327, 0.02077827, 0.02063613, 0.02924814,\n",
              "        0.01714993, 0.01695752, 0.01657043, 0.02220807, 0.01857381,\n",
              "        0.01861649, 0.03186111, 0.01792145, 0.02060056, 0.02276878,\n",
              "        0.02054639, 0.01775031, 0.02418227, 0.01676192, 0.01633263,\n",
              "        0.02926092, 0.01878181, 0.02067242, 0.02417073, 0.02256403,\n",
              "        0.02813725, 0.02149982, 0.02348127, 0.01693997, 0.01649508,\n",
              "        0.01647511, 0.0229382 , 0.01920042, 0.02126756, 0.02919784,\n",
              "        0.01888509, 0.02362103, 0.02232652, 0.02626176, 0.0252985 ,\n",
              "        0.01674404, 0.02273235, 0.01975093, 0.01654911, 0.02434597,\n",
              "        0.02260013, 0.02071657, 0.02640872, 0.0224956 , 0.02573738,\n",
              "        0.02137508, 0.02167001, 0.02126045, 0.0162066 , 0.01977506,\n",
              "        0.0214613 , 0.02314172, 0.01971717, 0.02303848, 0.01884909,\n",
              "        0.02273355, 0.02160659, 0.02124953, 0.02352519, 0.01657357,\n",
              "        0.01667709, 0.02712684, 0.01634812, 0.01973433, 0.0269134 ,\n",
              "        0.01939797, 0.01899047, 0.03197708, 0.02218823, 0.0263804 ,\n",
              "        0.02296848, 0.01647968, 0.02260756, 0.01705685, 0.01777997,\n",
              "        0.02425461, 0.01907034, 0.02332253, 0.02288609, 0.02237387,\n",
              "        0.02787957, 0.02004075, 0.02957006, 0.01668963, 0.01724644,\n",
              "        0.02178583, 0.0212575 , 0.01966624, 0.02353191, 0.02006226,\n",
              "        0.01861777, 0.0220716 , 0.02081008, 0.02896471, 0.02082124,\n",
              "        0.01635175, 0.02344146, 0.0170301 , 0.01654153, 0.02699704,\n",
              "        0.01868019, 0.01948957, 0.0251637 , 0.01891098, 0.02623248,\n",
              "        0.02029738, 0.02082458, 0.02056351, 0.0172183 , 0.01725974,\n",
              "        0.02011862, 0.01689653, 0.01858292, 0.02236757, 0.01805329,\n",
              "        0.01819253, 0.02223296, 0.01864095, 0.02617898]),\n",
              " 'std_score_time': array([1.28134727e-03, 8.19836383e-03, 7.28593796e-04, 1.77814258e-04,\n",
              "        8.08823931e-04, 8.45423221e-03, 5.66252981e-04, 1.16377355e-03,\n",
              "        1.09522080e-02, 6.37594982e-04, 9.57843536e-04, 2.38084636e-04,\n",
              "        8.33855958e-03, 6.00629532e-04, 1.06620355e-03, 1.23616955e-03,\n",
              "        7.62456357e-03, 4.13797161e-03, 1.07844114e-03, 2.55069449e-02,\n",
              "        1.01859968e-03, 1.99935495e-04, 7.80957966e-03, 9.50131456e-03,\n",
              "        6.37289417e-04, 2.70274507e-04, 1.33242884e-03, 6.03646580e-03,\n",
              "        1.57213334e-04, 2.22016139e-04, 1.26729023e-02, 6.12069546e-03,\n",
              "        4.44757155e-04, 1.21381250e-03, 9.75495358e-03, 1.08234945e-03,\n",
              "        1.75584936e-03, 7.36821505e-03, 1.05309414e-03, 3.27278614e-04,\n",
              "        3.84270590e-04, 1.01088119e-02, 1.04872580e-03, 6.00294141e-04,\n",
              "        8.74053811e-03, 8.12559197e-03, 1.10091452e-03, 3.48847123e-04,\n",
              "        9.71150366e-03, 7.03601997e-04, 3.27521308e-04, 4.02474533e-04,\n",
              "        8.83762710e-03, 5.63505475e-04, 3.21295920e-04, 9.33309814e-04,\n",
              "        2.30475767e-03, 1.46695940e-03, 1.92597273e-04, 1.19290292e-02,\n",
              "        9.13690921e-05, 5.50528818e-04, 2.06460027e-04, 7.12967384e-03,\n",
              "        7.86937980e-03, 8.84148321e-04, 1.37809944e-03, 6.09221654e-03,\n",
              "        1.15977856e-03, 1.31761638e-03, 6.48745086e-03, 8.72468853e-04,\n",
              "        1.32184782e-04, 1.55084134e-03, 1.05953909e-02, 2.21775751e-03,\n",
              "        2.51338392e-04, 5.87209036e-05, 8.64925989e-03, 8.20632419e-04,\n",
              "        3.79341986e-04, 1.30763978e-02, 2.15621977e-03, 7.24305293e-04,\n",
              "        1.74922623e-03, 6.51453022e-03, 2.18506433e-04, 1.26848418e-03,\n",
              "        2.54474174e-04, 9.82514027e-03, 3.85027844e-04, 1.26497574e-04,\n",
              "        8.38100805e-03, 9.36981383e-04, 2.28558451e-04, 7.46650567e-04,\n",
              "        6.95330433e-03, 3.76904632e-04, 2.38391921e-03, 3.96460301e-04,\n",
              "        1.10862515e-02, 5.14379921e-03, 4.48464878e-04, 4.77658186e-03,\n",
              "        5.28804832e-03, 1.15471271e-03, 2.53528654e-04, 8.53103598e-03,\n",
              "        5.40266820e-04, 1.79017625e-04, 9.69220209e-04, 1.01911062e-02,\n",
              "        1.05079167e-03, 5.47776253e-04, 7.26391462e-03, 8.21139132e-03,\n",
              "        6.55657289e-03, 1.19960847e-02, 1.46062599e-03, 6.74447417e-04,\n",
              "        1.11359564e-02, 6.87633482e-04, 5.49735974e-04, 3.93076731e-04,\n",
              "        1.05063121e-02, 1.17950992e-03, 7.12155474e-04, 9.07665403e-03,\n",
              "        6.15319223e-04, 2.09068751e-03, 6.93811818e-03, 2.44218220e-04,\n",
              "        1.90371011e-03, 5.69092119e-03, 1.39452851e-04, 1.06940277e-04,\n",
              "        1.79989662e-04, 1.08875714e-02, 9.88671600e-04, 1.39475651e-03,\n",
              "        7.18742393e-03, 1.03622868e-03, 2.72272032e-03, 7.53758185e-03,\n",
              "        1.94877519e-04, 2.22778167e-04, 7.53627381e-03, 7.68289993e-03,\n",
              "        3.19210087e-04, 3.53854510e-04, 1.08473261e-02, 5.23359452e-04,\n",
              "        8.45392527e-03, 4.44489966e-03, 7.86051030e-04, 9.55707927e-03,\n",
              "        8.15757757e-03, 1.56968941e-04, 4.38679484e-03, 6.64303334e-03,\n",
              "        3.75999437e-04, 4.05621309e-04, 8.52146255e-03, 8.93266781e-03,\n",
              "        2.66386665e-04, 8.18732242e-03, 1.85913873e-04, 1.04427987e-03,\n",
              "        5.18320038e-03, 4.65499162e-03, 3.86494134e-04, 8.00635043e-04,\n",
              "        7.01913748e-03, 9.08275784e-05, 2.39872043e-03, 5.83961181e-03,\n",
              "        1.17698671e-03, 7.84103295e-04, 1.01054301e-02, 1.10392080e-03,\n",
              "        4.51044515e-04, 1.32457740e-03, 8.91882873e-03, 4.67958658e-04,\n",
              "        1.75886116e-04, 6.87328738e-03, 5.39192577e-04, 2.36569117e-04,\n",
              "        9.65118417e-03, 6.36697490e-04, 5.66915125e-04, 1.00273825e-02,\n",
              "        3.77213468e-04, 6.18384838e-04, 6.05215855e-03, 5.42010501e-03,\n",
              "        8.71337789e-04, 8.18863795e-04, 1.00959277e-02, 1.29480264e-04,\n",
              "        3.16647936e-04, 5.49456447e-03, 1.24920274e-03, 7.84587292e-04,\n",
              "        1.12188354e-02, 6.46183021e-04, 1.21448072e-03, 3.17677511e-04,\n",
              "        6.69811098e-03, 1.12968324e-03, 2.51773785e-04, 1.00829875e-02,\n",
              "        4.47706087e-04, 2.81608735e-03, 4.72472261e-03, 1.96658981e-03,\n",
              "        2.17966959e-03, 8.07030911e-03, 7.36593104e-04, 2.86119898e-04,\n",
              "        9.68242702e-03, 3.44393590e-04, 4.01386199e-03, 6.66980806e-03,\n",
              "        1.10345390e-03, 1.26232239e-02, 7.59573581e-04, 3.68750441e-03,\n",
              "        4.17197651e-04, 4.02527746e-04, 1.51531136e-04, 8.09516911e-03,\n",
              "        3.00008365e-04, 4.07101508e-03, 9.72976021e-03, 3.89081280e-04,\n",
              "        2.55321796e-03, 1.18807364e-03, 7.84371963e-03, 8.50964121e-03,\n",
              "        2.27404766e-04, 7.41335403e-03, 5.34352742e-03, 2.46695749e-04,\n",
              "        8.66526034e-03, 6.89525852e-03, 3.22092042e-03, 7.36290355e-03,\n",
              "        2.11942000e-04, 8.64120506e-03, 8.95687973e-04, 2.05851671e-03,\n",
              "        9.59377601e-03, 1.53180224e-04, 5.66532456e-03, 6.47101662e-03,\n",
              "        7.38599146e-03, 1.16322886e-03, 5.21372733e-03, 2.68365266e-04,\n",
              "        2.73517842e-03, 5.51804576e-04, 1.36589253e-04, 5.50573680e-03,\n",
              "        3.98999390e-04, 1.75162312e-04, 1.22969193e-02, 2.57391424e-04,\n",
              "        6.96000480e-04, 8.54378498e-03, 1.05135309e-03, 2.94578727e-04,\n",
              "        1.28841477e-02, 1.76209499e-03, 9.07750417e-03, 2.34820492e-03,\n",
              "        3.53536549e-04, 9.73036983e-03, 1.00786313e-03, 8.89490642e-04,\n",
              "        7.78193228e-03, 2.97814388e-04, 8.82883800e-03, 7.78230132e-03,\n",
              "        6.27107912e-03, 9.28947946e-03, 3.12525490e-04, 1.09617778e-02,\n",
              "        2.37169887e-04, 7.41748048e-04, 9.58451381e-03, 6.90261273e-03,\n",
              "        7.35466117e-04, 8.06817568e-03, 2.62004089e-03, 2.96203190e-04,\n",
              "        7.93415321e-04, 1.09596475e-04, 9.68976183e-03, 1.81715227e-04,\n",
              "        1.32324966e-04, 6.98126598e-03, 8.25395680e-04, 2.89863084e-04,\n",
              "        1.07108531e-02, 5.30222542e-04, 1.23422224e-03, 7.79182157e-03,\n",
              "        3.08213338e-04, 7.82512497e-03, 3.68548010e-04, 1.36346700e-03,\n",
              "        3.78654181e-03, 1.89123732e-03, 7.95140303e-04, 6.51986645e-03,\n",
              "        2.98516719e-04, 1.20940481e-03, 5.53735494e-03, 2.48279909e-04,\n",
              "        2.88539482e-03, 8.49275927e-03, 4.61070475e-04, 9.46282592e-03]),\n",
              " 'param_colsample_bytree': masked_array(data=[0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
              "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7,\n",
              "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
              "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
              "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
              "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
              "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
              "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
              "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
              "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
              "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
              "                    0.7, 0.7, 0.7, 0.7, 0.7],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_gamma': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
              "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
              "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
              "                    0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0,\n",
              "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
              "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
              "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
              "                    0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0,\n",
              "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
              "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
              "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_learning_rate': masked_array(data=[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
              "                    0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
              "                    0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
              "                    0.4, 0.4, 0.4, 0.4, 0.4],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_depth': masked_array(data=[5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6,\n",
              "                    6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,\n",
              "                    5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6,\n",
              "                    6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,\n",
              "                    5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6,\n",
              "                    6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,\n",
              "                    5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6,\n",
              "                    6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,\n",
              "                    5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6,\n",
              "                    6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,\n",
              "                    5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6,\n",
              "                    6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,\n",
              "                    5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6,\n",
              "                    6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,\n",
              "                    5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6,\n",
              "                    6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7,\n",
              "                    5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6,\n",
              "                    6, 6, 7, 7, 7, 7, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_min_child_weight': masked_array(data=[0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n",
              "                    2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
              "                    0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n",
              "                    2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
              "                    0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n",
              "                    2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
              "                    0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n",
              "                    2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
              "                    0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n",
              "                    2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
              "                    0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n",
              "                    2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
              "                    0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n",
              "                    2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
              "                    0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n",
              "                    2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
              "                    0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1,\n",
              "                    2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.4,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.5,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.0,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.1,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.2,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.3,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 5,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 6,\n",
              "   'min_child_weight': 3},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 0},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 1},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 2},\n",
              "  {'colsample_bytree': 0.7,\n",
              "   'gamma': 0.2,\n",
              "   'learning_rate': 0.4,\n",
              "   'max_depth': 7,\n",
              "   'min_child_weight': 3}],\n",
              " 'split0_test_score': array([0.78531073, 0.78813559, 0.78107345, 0.78248588, 0.78813559,\n",
              "        0.77824859, 0.77824859, 0.78389831, 0.77966102, 0.77118644,\n",
              "        0.77542373, 0.78107345, 0.78389831, 0.77683616, 0.77683616,\n",
              "        0.76836158, 0.78248588, 0.76694915, 0.76836158, 0.76271186,\n",
              "        0.76271186, 0.75423729, 0.76553672, 0.77542373, 0.77824859,\n",
              "        0.77118644, 0.77118644, 0.76977401, 0.75988701, 0.76412429,\n",
              "        0.76694915, 0.76836158, 0.77824859, 0.75988701, 0.76129944,\n",
              "        0.75847458, 0.78389831, 0.79661017, 0.78107345, 0.77683616,\n",
              "        0.78954802, 0.77966102, 0.78248588, 0.7740113 , 0.76977401,\n",
              "        0.76694915, 0.7740113 , 0.77542373, 0.76694915, 0.78248588,\n",
              "        0.78389831, 0.76553672, 0.76694915, 0.7740113 , 0.76836158,\n",
              "        0.76694915, 0.76412429, 0.76836158, 0.76836158, 0.76977401,\n",
              "        0.76977401, 0.78107345, 0.77824859, 0.76271186, 0.76694915,\n",
              "        0.76129944, 0.75141243, 0.77542373, 0.76129944, 0.77259887,\n",
              "        0.76553672, 0.76836158, 0.78531073, 0.78531073, 0.78248588,\n",
              "        0.77259887, 0.77966102, 0.7740113 , 0.76977401, 0.77259887,\n",
              "        0.77118644, 0.7740113 , 0.77118644, 0.77966102, 0.7740113 ,\n",
              "        0.78107345, 0.77683616, 0.77824859, 0.77824859, 0.76271186,\n",
              "        0.76694915, 0.75988701, 0.76553672, 0.76977401, 0.75988701,\n",
              "        0.76836158, 0.76553672, 0.78248588, 0.77683616, 0.77542373,\n",
              "        0.76977401, 0.76977401, 0.76271186, 0.7740113 , 0.76129944,\n",
              "        0.78107345, 0.7740113 , 0.78248588, 0.78389831, 0.78672316,\n",
              "        0.77259887, 0.7740113 , 0.76836158, 0.76977401, 0.77966102,\n",
              "        0.77259887, 0.76553672, 0.76977401, 0.77259887, 0.77824859,\n",
              "        0.77824859, 0.77683616, 0.76694915, 0.76694915, 0.77683616,\n",
              "        0.76412429, 0.76836158, 0.75706215, 0.76553672, 0.76977401,\n",
              "        0.76271186, 0.76412429, 0.77824859, 0.75847458, 0.76271186,\n",
              "        0.75706215, 0.77824859, 0.76694915, 0.75564972, 0.76271186,\n",
              "        0.76836158, 0.75988701, 0.76129944, 0.75706215, 0.77259887,\n",
              "        0.77542373, 0.77542373, 0.7740113 , 0.77824859, 0.77118644,\n",
              "        0.77259887, 0.77824859, 0.77824859, 0.76694915, 0.76129944,\n",
              "        0.76412429, 0.7740113 , 0.77118644, 0.76694915, 0.77824859,\n",
              "        0.77259887, 0.76836158, 0.76694915, 0.76836158, 0.76836158,\n",
              "        0.76694915, 0.76836158, 0.76412429, 0.75564972, 0.74858757,\n",
              "        0.77542373, 0.75988701, 0.76553672, 0.77118644, 0.76271186,\n",
              "        0.75706215, 0.76977401, 0.76977401, 0.75847458, 0.75847458,\n",
              "        0.77683616, 0.77966102, 0.78107345, 0.77683616, 0.77118644,\n",
              "        0.76977401, 0.7740113 , 0.76694915, 0.77966102, 0.77824859,\n",
              "        0.76836158, 0.77259887, 0.76977401, 0.76271186, 0.77118644,\n",
              "        0.76836158, 0.77259887, 0.76553672, 0.75988701, 0.76271186,\n",
              "        0.77542373, 0.76129944, 0.76836158, 0.75706215, 0.7740113 ,\n",
              "        0.75847458, 0.76129944, 0.76977401, 0.75847458, 0.75847458,\n",
              "        0.76977401, 0.75      , 0.76412429, 0.77259887, 0.75988701,\n",
              "        0.75141243, 0.77824859, 0.78107345, 0.77542373, 0.76694915,\n",
              "        0.78107345, 0.77542373, 0.76412429, 0.77966102, 0.76977401,\n",
              "        0.76977401, 0.76977401, 0.76129944, 0.77966102, 0.75988701,\n",
              "        0.75988701, 0.77824859, 0.75706215, 0.75564972, 0.77118644,\n",
              "        0.76977401, 0.76694915, 0.76553672, 0.76977401, 0.77966102,\n",
              "        0.77542373, 0.76836158, 0.77542373, 0.76836158, 0.76977401,\n",
              "        0.75847458, 0.76271186, 0.77542373, 0.77259887, 0.76836158,\n",
              "        0.74858757, 0.76836158, 0.78248588, 0.77542373, 0.76977401,\n",
              "        0.76977401, 0.78107345, 0.76694915, 0.77259887, 0.76694915,\n",
              "        0.7740113 , 0.77118644, 0.77683616, 0.75988701, 0.76553672,\n",
              "        0.77824859, 0.76977401, 0.77824859, 0.7740113 , 0.77259887,\n",
              "        0.76271186, 0.76553672, 0.77118644, 0.76412429, 0.76553672,\n",
              "        0.76553672, 0.76412429, 0.77683616, 0.76836158, 0.78389831,\n",
              "        0.76129944, 0.76412429, 0.76412429, 0.75988701, 0.76836158,\n",
              "        0.76412429, 0.76412429, 0.76412429, 0.76553672, 0.78531073,\n",
              "        0.76412429, 0.77824859, 0.78107345, 0.77966102, 0.78248588,\n",
              "        0.77683616, 0.77542373, 0.77542373, 0.77259887, 0.77118644,\n",
              "        0.77824859, 0.77118644, 0.7740113 , 0.76412429, 0.77118644,\n",
              "        0.76694915, 0.75847458, 0.75564972, 0.77683616, 0.76977401,\n",
              "        0.76271186, 0.76836158, 0.77259887, 0.77542373, 0.76836158,\n",
              "        0.77683616, 0.75988701, 0.76836158, 0.76694915, 0.76412429,\n",
              "        0.76412429, 0.75423729, 0.76836158, 0.76977401]),\n",
              " 'split1_test_score': array([0.77966102, 0.78248588, 0.77824859, 0.78107345, 0.78248588,\n",
              "        0.78813559, 0.78389831, 0.77683616, 0.78672316, 0.78954802,\n",
              "        0.78954802, 0.78248588, 0.76412429, 0.79237288, 0.78248588,\n",
              "        0.76836158, 0.78531073, 0.77683616, 0.77966102, 0.77118644,\n",
              "        0.77966102, 0.79378531, 0.79378531, 0.77259887, 0.77824859,\n",
              "        0.78672316, 0.78248588, 0.7740113 , 0.79378531, 0.79378531,\n",
              "        0.77824859, 0.78954802, 0.78531073, 0.77824859, 0.78813559,\n",
              "        0.79096045, 0.78672316, 0.78813559, 0.78672316, 0.78672316,\n",
              "        0.7740113 , 0.77824859, 0.78248588, 0.78248588, 0.78531073,\n",
              "        0.78248588, 0.78531073, 0.78954802, 0.78389831, 0.78389831,\n",
              "        0.78107345, 0.77542373, 0.78531073, 0.77683616, 0.77966102,\n",
              "        0.77966102, 0.78107345, 0.78672316, 0.78389831, 0.77542373,\n",
              "        0.77824859, 0.78107345, 0.7740113 , 0.76694915, 0.78672316,\n",
              "        0.78389831, 0.7740113 , 0.77542373, 0.78531073, 0.77683616,\n",
              "        0.79237288, 0.76836158, 0.78107345, 0.78813559, 0.79661017,\n",
              "        0.78248588, 0.77966102, 0.78107345, 0.77966102, 0.7740113 ,\n",
              "        0.78248588, 0.78954802, 0.78813559, 0.78672316, 0.77824859,\n",
              "        0.78248588, 0.76553672, 0.77118644, 0.78248588, 0.78389831,\n",
              "        0.78107345, 0.76271186, 0.78531073, 0.78672316, 0.77966102,\n",
              "        0.77683616, 0.77966102, 0.77683616, 0.78389831, 0.78248588,\n",
              "        0.77542373, 0.77966102, 0.78248588, 0.77683616, 0.78531073,\n",
              "        0.78248588, 0.78672316, 0.79237288, 0.79096045, 0.78107345,\n",
              "        0.78389831, 0.78813559, 0.78531073, 0.78672316, 0.78813559,\n",
              "        0.78531073, 0.77683616, 0.77966102, 0.79519774, 0.79096045,\n",
              "        0.78672316, 0.78954802, 0.77542373, 0.78389831, 0.77542373,\n",
              "        0.78107345, 0.78813559, 0.77966102, 0.78672316, 0.78248588,\n",
              "        0.78248588, 0.77966102, 0.77683616, 0.77824859, 0.78107345,\n",
              "        0.77824859, 0.77683616, 0.77542373, 0.78389831, 0.77683616,\n",
              "        0.78107345, 0.77683616, 0.78389831, 0.79096045, 0.78531073,\n",
              "        0.77824859, 0.79237288, 0.77542373, 0.80084746, 0.78813559,\n",
              "        0.79943503, 0.78248588, 0.78813559, 0.78531073, 0.78531073,\n",
              "        0.78672316, 0.78107345, 0.77259887, 0.77966102, 0.77683616,\n",
              "        0.7980226 , 0.78389831, 0.78107345, 0.78672316, 0.78672316,\n",
              "        0.78672316, 0.78248588, 0.78813559, 0.80367232, 0.79378531,\n",
              "        0.78389831, 0.78107345, 0.77966102, 0.77259887, 0.78248588,\n",
              "        0.79378531, 0.78248588, 0.77966102, 0.78954802, 0.78389831,\n",
              "        0.78813559, 0.78389831, 0.78672316, 0.78107345, 0.78389831,\n",
              "        0.78107345, 0.78248588, 0.78107345, 0.78248588, 0.77683616,\n",
              "        0.78107345, 0.78813559, 0.78813559, 0.77824859, 0.78248588,\n",
              "        0.78248588, 0.78813559, 0.78389831, 0.77824859, 0.77966102,\n",
              "        0.77118644, 0.77824859, 0.77542373, 0.78531073, 0.79096045,\n",
              "        0.78389831, 0.78248588, 0.78672316, 0.77966102, 0.77824859,\n",
              "        0.77118644, 0.79096045, 0.78954802, 0.77683616, 0.79237288,\n",
              "        0.77824859, 0.78954802, 0.78954802, 0.78107345, 0.78813559,\n",
              "        0.78531073, 0.79237288, 0.79378531, 0.79237288, 0.7980226 ,\n",
              "        0.7740113 , 0.78107345, 0.78389831, 0.79237288, 0.77966102,\n",
              "        0.78531073, 0.79096045, 0.78248588, 0.78531073, 0.78531073,\n",
              "        0.78531073, 0.78813559, 0.78248588, 0.78389831, 0.77824859,\n",
              "        0.78107345, 0.78672316, 0.76412429, 0.78389831, 0.77824859,\n",
              "        0.7740113 , 0.78389831, 0.78954802, 0.77966102, 0.79519774,\n",
              "        0.78248588, 0.78389831, 0.78531073, 0.79096045, 0.78813559,\n",
              "        0.79519774, 0.78248588, 0.79237288, 0.78954802, 0.79661017,\n",
              "        0.77683616, 0.78248588, 0.78389831, 0.78672316, 0.79096045,\n",
              "        0.78813559, 0.79096045, 0.79378531, 0.78672316, 0.78389831,\n",
              "        0.78954802, 0.78672316, 0.78954802, 0.79096045, 0.78813559,\n",
              "        0.78107345, 0.78672316, 0.78389831, 0.78107345, 0.78389831,\n",
              "        0.79096045, 0.78107345, 0.78672316, 0.78248588, 0.78672316,\n",
              "        0.78248588, 0.78107345, 0.77966102, 0.78813559, 0.79661017,\n",
              "        0.79096045, 0.78248588, 0.7980226 , 0.78107345, 0.78389831,\n",
              "        0.78672316, 0.78248588, 0.78813559, 0.79096045, 0.79096045,\n",
              "        0.78954802, 0.79661017, 0.78248588, 0.79237288, 0.76836158,\n",
              "        0.77683616, 0.77683616, 0.78813559, 0.78389831, 0.78389831,\n",
              "        0.77683616, 0.78389831, 0.78954802, 0.79096045, 0.78248588,\n",
              "        0.78813559, 0.77542373, 0.78389831, 0.79096045, 0.77118644,\n",
              "        0.78672316, 0.7740113 , 0.78531073, 0.78672316]),\n",
              " 'split2_test_score': array([0.77259887, 0.78389831, 0.76977401, 0.77542373, 0.77259887,\n",
              "        0.7740113 , 0.77824859, 0.77259887, 0.76412429, 0.7740113 ,\n",
              "        0.77542373, 0.76553672, 0.76977401, 0.78531073, 0.76977401,\n",
              "        0.78107345, 0.76553672, 0.7740113 , 0.76694915, 0.77118644,\n",
              "        0.75988701, 0.77542373, 0.77966102, 0.77966102, 0.76553672,\n",
              "        0.76836158, 0.77118644, 0.76412429, 0.77824859, 0.76977401,\n",
              "        0.76129944, 0.76412429, 0.75988701, 0.75706215, 0.75564972,\n",
              "        0.76553672, 0.77118644, 0.78389831, 0.77683616, 0.78531073,\n",
              "        0.77118644, 0.77118644, 0.77118644, 0.77824859, 0.76553672,\n",
              "        0.77824859, 0.78389831, 0.77966102, 0.76977401, 0.7740113 ,\n",
              "        0.76694915, 0.77259887, 0.77259887, 0.78672316, 0.76977401,\n",
              "        0.7740113 , 0.77824859, 0.78107345, 0.76553672, 0.77259887,\n",
              "        0.76977401, 0.77683616, 0.77542373, 0.76694915, 0.75423729,\n",
              "        0.76553672, 0.7740113 , 0.75847458, 0.76271186, 0.77542373,\n",
              "        0.77966102, 0.75423729, 0.78107345, 0.77824859, 0.77824859,\n",
              "        0.77824859, 0.77683616, 0.77824859, 0.78107345, 0.7740113 ,\n",
              "        0.7740113 , 0.77683616, 0.7740113 , 0.77259887, 0.7740113 ,\n",
              "        0.77542373, 0.76977401, 0.77118644, 0.76836158, 0.77542373,\n",
              "        0.77118644, 0.77118644, 0.77542373, 0.76977401, 0.76553672,\n",
              "        0.77824859, 0.79096045, 0.76694915, 0.76977401, 0.76694915,\n",
              "        0.76836158, 0.76412429, 0.76412429, 0.76977401, 0.7740113 ,\n",
              "        0.76977401, 0.76412429, 0.76271186, 0.77259887, 0.78389831,\n",
              "        0.78672316, 0.77966102, 0.76977401, 0.7740113 , 0.77824859,\n",
              "        0.78672316, 0.76553672, 0.7740113 , 0.77542373, 0.77542373,\n",
              "        0.77824859, 0.76412429, 0.77824859, 0.77542373, 0.77118644,\n",
              "        0.75706215, 0.76553672, 0.75988701, 0.78248588, 0.77118644,\n",
              "        0.77118644, 0.76271186, 0.76553672, 0.77542373, 0.77683616,\n",
              "        0.77118644, 0.76271186, 0.77259887, 0.77259887, 0.76553672,\n",
              "        0.77542373, 0.76129944, 0.75282486, 0.7740113 , 0.78531073,\n",
              "        0.78389831, 0.78531073, 0.77683616, 0.77683616, 0.77542373,\n",
              "        0.77542373, 0.77259887, 0.76977401, 0.77542373, 0.76412429,\n",
              "        0.76836158, 0.77259887, 0.77118644, 0.77259887, 0.77542373,\n",
              "        0.76836158, 0.77259887, 0.76836158, 0.76977401, 0.77259887,\n",
              "        0.76694915, 0.75847458, 0.77259887, 0.76977401, 0.76412429,\n",
              "        0.77683616, 0.77966102, 0.76977401, 0.76977401, 0.76977401,\n",
              "        0.76836158, 0.7740113 , 0.76271186, 0.77259887, 0.75847458,\n",
              "        0.77966102, 0.78248588, 0.78531073, 0.77542373, 0.76977401,\n",
              "        0.78248588, 0.77259887, 0.78248588, 0.77259887, 0.77259887,\n",
              "        0.76129944, 0.76553672, 0.77966102, 0.77824859, 0.78531073,\n",
              "        0.78954802, 0.77966102, 0.76977401, 0.77118644, 0.76553672,\n",
              "        0.77118644, 0.7740113 , 0.76977401, 0.7740113 , 0.78107345,\n",
              "        0.76271186, 0.75988701, 0.78248588, 0.76271186, 0.78389831,\n",
              "        0.77259887, 0.76977401, 0.76553672, 0.76553672, 0.76977401,\n",
              "        0.76553672, 0.76977401, 0.77683616, 0.78107345, 0.77683616,\n",
              "        0.76553672, 0.76836158, 0.77683616, 0.78813559, 0.76694915,\n",
              "        0.76553672, 0.76694915, 0.78389831, 0.7740113 , 0.77824859,\n",
              "        0.77118644, 0.77683616, 0.76694915, 0.77259887, 0.76412429,\n",
              "        0.7740113 , 0.77542373, 0.77259887, 0.76553672, 0.75282486,\n",
              "        0.7740113 , 0.76977401, 0.77542373, 0.7740113 , 0.76271186,\n",
              "        0.76977401, 0.74576271, 0.77118644, 0.76553672, 0.7740113 ,\n",
              "        0.75847458, 0.76553672, 0.77966102, 0.78672316, 0.78954802,\n",
              "        0.78672316, 0.76412429, 0.77118644, 0.77118644, 0.76977401,\n",
              "        0.77824859, 0.77259887, 0.76977401, 0.76977401, 0.78813559,\n",
              "        0.77966102, 0.76553672, 0.77259887, 0.77259887, 0.76553672,\n",
              "        0.7740113 , 0.76836158, 0.77824859, 0.76694915, 0.76694915,\n",
              "        0.76412429, 0.76412429, 0.77683616, 0.77118644, 0.76977401,\n",
              "        0.76836158, 0.76553672, 0.76412429, 0.78248588, 0.75988701,\n",
              "        0.76553672, 0.7740113 , 0.7740113 , 0.77966102, 0.78954802,\n",
              "        0.78389831, 0.77824859, 0.77118644, 0.76977401, 0.77118644,\n",
              "        0.77966102, 0.77683616, 0.77966102, 0.76553672, 0.77118644,\n",
              "        0.7740113 , 0.76553672, 0.77966102, 0.77259887, 0.76836158,\n",
              "        0.78107345, 0.76553672, 0.77683616, 0.77118644, 0.77683616,\n",
              "        0.77542373, 0.76836158, 0.76412429, 0.77824859, 0.77966102,\n",
              "        0.76977401, 0.77259887, 0.77824859, 0.77824859, 0.77259887,\n",
              "        0.76553672, 0.76694915, 0.77824859, 0.76694915]),\n",
              " 'split3_test_score': array([0.77259887, 0.77824859, 0.76412429, 0.76694915, 0.77118644,\n",
              "        0.76836158, 0.76694915, 0.75988701, 0.76271186, 0.77259887,\n",
              "        0.75564972, 0.76977401, 0.76271186, 0.7740113 , 0.76412429,\n",
              "        0.76553672, 0.76836158, 0.76977401, 0.75706215, 0.75847458,\n",
              "        0.76694915, 0.76129944, 0.76271186, 0.76836158, 0.75847458,\n",
              "        0.77683616, 0.75564972, 0.76271186, 0.75564972, 0.75847458,\n",
              "        0.76271186, 0.76412429, 0.75988701, 0.76553672, 0.75847458,\n",
              "        0.75847458, 0.77118644, 0.77824859, 0.78248588, 0.77118644,\n",
              "        0.77683616, 0.7740113 , 0.76553672, 0.75847458, 0.76553672,\n",
              "        0.77118644, 0.76977401, 0.76271186, 0.75706215, 0.76271186,\n",
              "        0.76129944, 0.76271186, 0.76977401, 0.76412429, 0.76271186,\n",
              "        0.75282486, 0.76412429, 0.76694915, 0.76271186, 0.76836158,\n",
              "        0.75988701, 0.75564972, 0.76129944, 0.75847458, 0.75423729,\n",
              "        0.75423729, 0.76553672, 0.76836158, 0.75988701, 0.76412429,\n",
              "        0.76412429, 0.76271186, 0.75564972, 0.75564972, 0.77118644,\n",
              "        0.76836158, 0.76412429, 0.77259887, 0.76977401, 0.76129944,\n",
              "        0.77259887, 0.76129944, 0.75988701, 0.76553672, 0.76836158,\n",
              "        0.76977401, 0.75564972, 0.75423729, 0.75988701, 0.76977401,\n",
              "        0.76412429, 0.7740113 , 0.76836158, 0.76553672, 0.75847458,\n",
              "        0.75988701, 0.75988701, 0.76977401, 0.76694915, 0.76412429,\n",
              "        0.76836158, 0.76694915, 0.76412429, 0.76412429, 0.76553672,\n",
              "        0.76129944, 0.76129944, 0.76271186, 0.76836158, 0.76412429,\n",
              "        0.77118644, 0.77259887, 0.76694915, 0.76129944, 0.76836158,\n",
              "        0.77259887, 0.76412429, 0.76694915, 0.76836158, 0.77542373,\n",
              "        0.7740113 , 0.75847458, 0.76694915, 0.76412429, 0.77118644,\n",
              "        0.76553672, 0.76129944, 0.76412429, 0.76271186, 0.75847458,\n",
              "        0.76694915, 0.76553672, 0.76836158, 0.77118644, 0.75423729,\n",
              "        0.75988701, 0.76553672, 0.75      , 0.76977401, 0.75847458,\n",
              "        0.75282486, 0.77118644, 0.74858757, 0.74858757, 0.77542373,\n",
              "        0.75847458, 0.76694915, 0.76977401, 0.7740113 , 0.76412429,\n",
              "        0.76271186, 0.7740113 , 0.75988701, 0.76694915, 0.76836158,\n",
              "        0.77542373, 0.76977401, 0.77118644, 0.77824859, 0.76553672,\n",
              "        0.76977401, 0.76694915, 0.76271186, 0.76553672, 0.75423729,\n",
              "        0.75141243, 0.75706215, 0.76271186, 0.75564972, 0.76412429,\n",
              "        0.76694915, 0.76977401, 0.75847458, 0.76694915, 0.75      ,\n",
              "        0.76412429, 0.76271186, 0.74576271, 0.75847458, 0.76412429,\n",
              "        0.76694915, 0.75282486, 0.75423729, 0.76836158, 0.76271186,\n",
              "        0.76129944, 0.76836158, 0.7740113 , 0.75988701, 0.76836158,\n",
              "        0.76412429, 0.75988701, 0.7740113 , 0.75564972, 0.76977401,\n",
              "        0.77259887, 0.76977401, 0.76977401, 0.76129944, 0.76129944,\n",
              "        0.75988701, 0.75      , 0.76694915, 0.76553672, 0.75847458,\n",
              "        0.76271186, 0.75564972, 0.75423729, 0.75282486, 0.76977401,\n",
              "        0.75988701, 0.76694915, 0.76553672, 0.76694915, 0.75282486,\n",
              "        0.76412429, 0.77966102, 0.77683616, 0.77542373, 0.77259887,\n",
              "        0.77966102, 0.76836158, 0.77824859, 0.77259887, 0.77966102,\n",
              "        0.76977401, 0.75847458, 0.76836158, 0.76836158, 0.76412429,\n",
              "        0.75847458, 0.77259887, 0.77259887, 0.75282486, 0.77542373,\n",
              "        0.76836158, 0.77118644, 0.76694915, 0.76836158, 0.76836158,\n",
              "        0.77259887, 0.75706215, 0.75282486, 0.75988701, 0.76412429,\n",
              "        0.76553672, 0.75988701, 0.74858757, 0.75564972, 0.75706215,\n",
              "        0.7740113 , 0.75282486, 0.76553672, 0.77259887, 0.77542373,\n",
              "        0.77966102, 0.76977401, 0.77542373, 0.77683616, 0.78531073,\n",
              "        0.7740113 , 0.7740113 , 0.76694915, 0.77542373, 0.77259887,\n",
              "        0.76553672, 0.76412429, 0.76129944, 0.76836158, 0.76129944,\n",
              "        0.76129944, 0.76977401, 0.7740113 , 0.75423729, 0.76271186,\n",
              "        0.76271186, 0.76553672, 0.75564972, 0.76129944, 0.76129944,\n",
              "        0.76271186, 0.76412429, 0.75      , 0.76271186, 0.75706215,\n",
              "        0.76271186, 0.75988701, 0.75141243, 0.77824859, 0.78107345,\n",
              "        0.76694915, 0.76836158, 0.78248588, 0.78248588, 0.77966102,\n",
              "        0.78389831, 0.77259887, 0.76836158, 0.77259887, 0.77824859,\n",
              "        0.76977401, 0.78389831, 0.76836158, 0.76977401, 0.77259887,\n",
              "        0.75706215, 0.76553672, 0.7740113 , 0.75847458, 0.76412429,\n",
              "        0.76694915, 0.76694915, 0.76836158, 0.75706215, 0.76694915,\n",
              "        0.75847458, 0.75847458, 0.75282486, 0.75423729, 0.76271186,\n",
              "        0.76694915, 0.75988701, 0.75706215, 0.75847458]),\n",
              " 'split4_test_score': array([0.78500707, 0.78783593, 0.78783593, 0.79207921, 0.78217822,\n",
              "        0.78076379, 0.78217822, 0.78359264, 0.78359264, 0.77652051,\n",
              "        0.78217822, 0.7864215 , 0.78783593, 0.76803395, 0.77934936,\n",
              "        0.78217822, 0.78359264, 0.7864215 , 0.77934936, 0.78783593,\n",
              "        0.78500707, 0.78783593, 0.7864215 , 0.77934936, 0.78076379,\n",
              "        0.77369165, 0.78500707, 0.78500707, 0.78217822, 0.79066478,\n",
              "        0.78783593, 0.79207921, 0.77652051, 0.78217822, 0.78359264,\n",
              "        0.79066478, 0.78359264, 0.7864215 , 0.78359264, 0.7864215 ,\n",
              "        0.78500707, 0.78217822, 0.78076379, 0.77934936, 0.78076379,\n",
              "        0.7864215 , 0.77369165, 0.78076379, 0.77934936, 0.77227723,\n",
              "        0.77934936, 0.77652051, 0.78500707, 0.77934936, 0.77793494,\n",
              "        0.7864215 , 0.78359264, 0.78359264, 0.78500707, 0.77793494,\n",
              "        0.78076379, 0.78217822, 0.7864215 , 0.78500707, 0.78359264,\n",
              "        0.78217822, 0.7708628 , 0.79066478, 0.78783593, 0.78359264,\n",
              "        0.79207921, 0.78217822, 0.77652051, 0.78925035, 0.79490806,\n",
              "        0.78500707, 0.77652051, 0.78217822, 0.76520509, 0.77510608,\n",
              "        0.79066478, 0.78076379, 0.77369165, 0.7864215 , 0.77793494,\n",
              "        0.77793494, 0.77934936, 0.78217822, 0.79207921, 0.78925035,\n",
              "        0.78076379, 0.78500707, 0.7864215 , 0.76944837, 0.78925035,\n",
              "        0.79066478, 0.78925035, 0.78500707, 0.77652051, 0.78500707,\n",
              "        0.78217822, 0.78783593, 0.78500707, 0.78925035, 0.79066478,\n",
              "        0.79632249, 0.79632249, 0.79207921, 0.80056577, 0.79490806,\n",
              "        0.78500707, 0.78217822, 0.77652051, 0.78359264, 0.78783593,\n",
              "        0.77793494, 0.78359264, 0.78500707, 0.78500707, 0.77793494,\n",
              "        0.78076379, 0.79632249, 0.78925035, 0.78925035, 0.78783593,\n",
              "        0.79632249, 0.7864215 , 0.80056577, 0.79632249, 0.79773692,\n",
              "        0.78925035, 0.78359264, 0.78500707, 0.7864215 , 0.77227723,\n",
              "        0.78217822, 0.79349364, 0.7864215 , 0.78359264, 0.78500707,\n",
              "        0.79349364, 0.78925035, 0.78076379, 0.78925035, 0.79207921,\n",
              "        0.78359264, 0.79066478, 0.78217822, 0.78783593, 0.78076379,\n",
              "        0.78500707, 0.78359264, 0.78500707, 0.78359264, 0.78359264,\n",
              "        0.78217822, 0.79066478, 0.79632249, 0.79066478, 0.78076379,\n",
              "        0.78925035, 0.79632249, 0.79773692, 0.78359264, 0.78783593,\n",
              "        0.78783593, 0.78783593, 0.78500707, 0.78783593, 0.78359264,\n",
              "        0.78359264, 0.78500707, 0.79915134, 0.78076379, 0.8019802 ,\n",
              "        0.78217822, 0.78783593, 0.79490806, 0.78076379, 0.78783593,\n",
              "        0.79207921, 0.78925035, 0.79207921, 0.7864215 , 0.78925035,\n",
              "        0.77934936, 0.7864215 , 0.78076379, 0.78500707, 0.78783593,\n",
              "        0.78359264, 0.7864215 , 0.78500707, 0.78359264, 0.79490806,\n",
              "        0.77369165, 0.78925035, 0.78500707, 0.78359264, 0.78500707,\n",
              "        0.7864215 , 0.77369165, 0.78217822, 0.79349364, 0.77793494,\n",
              "        0.77652051, 0.77934936, 0.77934936, 0.78500707, 0.79490806,\n",
              "        0.79066478, 0.79349364, 0.79490806, 0.77369165, 0.79349364,\n",
              "        0.79915134, 0.78500707, 0.77793494, 0.78217822, 0.78359264,\n",
              "        0.79349364, 0.7864215 , 0.77793494, 0.78359264, 0.78783593,\n",
              "        0.78925035, 0.7864215 , 0.78217822, 0.78359264, 0.77793494,\n",
              "        0.78076379, 0.77934936, 0.79773692, 0.78783593, 0.78500707,\n",
              "        0.78925035, 0.79632249, 0.7864215 , 0.78783593, 0.78783593,\n",
              "        0.78783593, 0.78359264, 0.79066478, 0.78925035, 0.79066478,\n",
              "        0.78925035, 0.78500707, 0.77652051, 0.78783593, 0.78359264,\n",
              "        0.78359264, 0.77510608, 0.77934936, 0.79207921, 0.78076379,\n",
              "        0.78076379, 0.78783593, 0.77793494, 0.78076379, 0.78076379,\n",
              "        0.79066478, 0.77934936, 0.77793494, 0.79349364, 0.78500707,\n",
              "        0.79490806, 0.79066478, 0.77652051, 0.7864215 , 0.7864215 ,\n",
              "        0.78359264, 0.77934936, 0.77793494, 0.78359264, 0.78500707,\n",
              "        0.79349364, 0.77652051, 0.78500707, 0.79490806, 0.77934936,\n",
              "        0.79066478, 0.77934936, 0.79632249, 0.78925035, 0.78925035,\n",
              "        0.78359264, 0.79207921, 0.78783593, 0.78783593, 0.78783593,\n",
              "        0.78076379, 0.7864215 , 0.78925035, 0.77793494, 0.78783593,\n",
              "        0.79490806, 0.77934936, 0.79066478, 0.77793494, 0.78217822,\n",
              "        0.77793494, 0.78500707, 0.78359264, 0.79207921, 0.77793494,\n",
              "        0.78783593, 0.78925035, 0.79349364, 0.79349364, 0.7864215 ,\n",
              "        0.7864215 , 0.78783593, 0.78925035, 0.78925035, 0.78500707,\n",
              "        0.77934936, 0.78500707, 0.78500707, 0.77510608, 0.7864215 ,\n",
              "        0.78359264, 0.78217822, 0.78783593, 0.78359264]),\n",
              " 'mean_test_score': array([0.77903531, 0.78412086, 0.77621125, 0.77960228, 0.779317  ,\n",
              "        0.77790417, 0.77790457, 0.7753626 , 0.7753626 , 0.77677303,\n",
              "        0.77564468, 0.77705831, 0.77366888, 0.779313  , 0.77451394,\n",
              "        0.77310231, 0.77705751, 0.77479842, 0.77027665, 0.77027905,\n",
              "        0.77084322, 0.77451634, 0.77762328, 0.77507891, 0.77225445,\n",
              "        0.7753598 , 0.77310311, 0.77112571, 0.77394977, 0.77536459,\n",
              "        0.77140899, 0.77564748, 0.77197077, 0.76858254, 0.76943039,\n",
              "        0.77282222, 0.7793174 , 0.78666283, 0.78214226, 0.7812956 ,\n",
              "        0.7793178 , 0.77705711, 0.77649174, 0.77451394, 0.7733844 ,\n",
              "        0.77705831, 0.7773372 , 0.77762168, 0.7714066 , 0.77507691,\n",
              "        0.77451394, 0.77055834, 0.77592797, 0.77620886, 0.77168868,\n",
              "        0.77197357, 0.77423265, 0.77734   , 0.77310311, 0.77281863,\n",
              "        0.77168948, 0.7753622 , 0.77508091, 0.76801836, 0.76914791,\n",
              "        0.76942999, 0.76716691, 0.77366968, 0.77140899, 0.77451514,\n",
              "        0.77875482, 0.76717011, 0.77592557, 0.779319  , 0.78468783,\n",
              "        0.7773404 , 0.7753606 , 0.77762208, 0.77309752, 0.7714054 ,\n",
              "        0.77818945, 0.77649174, 0.7733824 , 0.77818825, 0.77451354,\n",
              "        0.7773384 , 0.76942919, 0.77140739, 0.77621245, 0.77621165,\n",
              "        0.77281942, 0.77056074, 0.77621085, 0.77225126, 0.77056194,\n",
              "        0.77479962, 0.77705911, 0.77621045, 0.77479563, 0.77479802,\n",
              "        0.77281982, 0.77366888, 0.77169068, 0.77479922, 0.77536459,\n",
              "        0.77819105, 0.77649614, 0.77847234, 0.783277  , 0.78214545,\n",
              "        0.77988277, 0.779317  , 0.7733832 , 0.77508011, 0.78044854,\n",
              "        0.77903331, 0.77112531, 0.77508051, 0.7793178 , 0.77959829,\n",
              "        0.77959909, 0.77706111, 0.7753642 , 0.77592917, 0.77649374,\n",
              "        0.77282382, 0.77395097, 0.77226005, 0.77875602, 0.77593156,\n",
              "        0.77451674, 0.77112531, 0.77479802, 0.77395097, 0.7694272 ,\n",
              "        0.76971248, 0.77536539, 0.77027865, 0.77310271, 0.76971328,\n",
              "        0.77423545, 0.77169188, 0.76547479, 0.77197436, 0.78214466,\n",
              "        0.77592757, 0.78214426, 0.77564468, 0.78355589, 0.77592677,\n",
              "        0.77903531, 0.77818746, 0.77621045, 0.77564508, 0.77253774,\n",
              "        0.7753622 , 0.77762448, 0.77649614, 0.77762448, 0.7753618 ,\n",
              "        0.77960148, 0.77762608, 0.77536659, 0.77479763, 0.77395137,\n",
              "        0.77197396, 0.77084402, 0.77451554, 0.77451634, 0.77084282,\n",
              "        0.77734   , 0.77508051, 0.77451953, 0.77225445, 0.77339039,\n",
              "        0.77310231, 0.7753638 , 0.77056353, 0.77197197, 0.77056154,\n",
              "        0.78073223, 0.77762408, 0.77988477, 0.77762328, 0.7753642 ,\n",
              "        0.77479643, 0.77677583, 0.77705671, 0.77592797, 0.77677622,\n",
              "        0.77169028, 0.77451594, 0.7793178 , 0.77169028, 0.78073302,\n",
              "        0.7773372 , 0.77988397, 0.77479802, 0.77084282, 0.77084322,\n",
              "        0.77282102, 0.7674502 , 0.77253734, 0.77508291, 0.77649094,\n",
              "        0.76886342, 0.76773428, 0.77451394, 0.76773588, 0.77706071,\n",
              "        0.77282222, 0.77423545, 0.77593076, 0.77112251, 0.77367048,\n",
              "        0.77169468, 0.78044774, 0.78044574, 0.77903451, 0.77762248,\n",
              "        0.78101511, 0.77818825, 0.77818586, 0.7832722 , 0.78044854,\n",
              "        0.77366928, 0.77253854, 0.77592717, 0.77959988, 0.77197117,\n",
              "        0.77112451, 0.77959869, 0.77536659, 0.77084402, 0.77621045,\n",
              "        0.7773416 , 0.77960348, 0.77479842, 0.77508131, 0.77338639,\n",
              "        0.77818865, 0.77310271, 0.77169228, 0.77508171, 0.77310471,\n",
              "        0.77140939, 0.76745339, 0.77225325, 0.77225645, 0.77564508,\n",
              "        0.76943039, 0.76914551, 0.77846874, 0.78355708, 0.78072903,\n",
              "        0.78242394, 0.77705871, 0.77677343, 0.77818666, 0.77988157,\n",
              "        0.77875443, 0.77592637, 0.77507851, 0.77706031, 0.78044774,\n",
              "        0.781298  , 0.77621205, 0.77649054, 0.77762328, 0.77395097,\n",
              "        0.77423265, 0.77394897, 0.77818586, 0.77197277, 0.77366808,\n",
              "        0.77338799, 0.7714058 , 0.77564548, 0.77536579, 0.77564388,\n",
              "        0.77479962, 0.77084162, 0.77225885, 0.7753642 , 0.77225685,\n",
              "        0.77169028, 0.77423505, 0.77140899, 0.77988357, 0.78807566,\n",
              "        0.7773392 , 0.77875323, 0.78440374, 0.77818586, 0.78101351,\n",
              "        0.78440534, 0.7773388 , 0.78044934, 0.77592597, 0.77875203,\n",
              "        0.77790337, 0.78044774, 0.77762248, 0.77818985, 0.77168868,\n",
              "        0.77395137, 0.77112691, 0.77762528, 0.77677782, 0.77621085,\n",
              "        0.77366848, 0.77508131, 0.77677662, 0.77818905, 0.77649294,\n",
              "        0.77451394, 0.77027825, 0.77366808, 0.77310031, 0.77140859,\n",
              "        0.7733852 , 0.76745259, 0.7753638 , 0.77310271]),\n",
              " 'std_test_score': array([0.00562654, 0.00366404, 0.00837206, 0.00829114, 0.00643794,\n",
              "        0.00662108, 0.00590672, 0.00883058, 0.01001612, 0.00662608,\n",
              "        0.01127729, 0.0079882 , 0.01031185, 0.00857896, 0.00667439,\n",
              "        0.00704412, 0.00835031, 0.00673385, 0.00848226, 0.01006478,\n",
              "        0.00979479, 0.01506954, 0.0119265 , 0.00425733, 0.00870955,\n",
              "        0.00633215, 0.01040873, 0.00803316, 0.01422877, 0.01425686,\n",
              "        0.01014256, 0.01250503, 0.01029661, 0.00995875, 0.01361252,\n",
              "        0.01491402, 0.00672804, 0.00599365, 0.00324048, 0.00622794,\n",
              "        0.00689147, 0.00395392, 0.00690316, 0.00846634, 0.00815965,\n",
              "        0.00714449, 0.0061348 , 0.00875675, 0.00945968, 0.00767565,\n",
              "        0.00879004, 0.00548027, 0.00774648, 0.0073712 , 0.00629115,\n",
              "        0.01152311, 0.00842486, 0.00811985, 0.00944405, 0.00352552,\n",
              "        0.00737566, 0.01002446, 0.00812199, 0.00905699, 0.01390703,\n",
              "        0.01169556, 0.00846418, 0.01052667, 0.01243947, 0.00632859,\n",
              "        0.01226852, 0.00911281, 0.01051234, 0.01243902, 0.0097488 ,\n",
              "        0.0061511 , 0.0057752 , 0.00377712, 0.00618186, 0.0051153 ,\n",
              "        0.00737356, 0.00922816, 0.00900106, 0.00817438, 0.00357792,\n",
              "        0.00450974, 0.00846661, 0.00956789, 0.01116613, 0.00952261,\n",
              "        0.00698533, 0.00890537, 0.0085233 , 0.00741149, 0.01197799,\n",
              "        0.01031097, 0.01246026, 0.00699074, 0.00594612, 0.00823714,\n",
              "        0.00535516, 0.00880948, 0.00988921, 0.00840014, 0.01121845,\n",
              "        0.01193043, 0.01332556, 0.01335115, 0.01178826, 0.01012742,\n",
              "        0.00660084, 0.00564546, 0.00680806, 0.00924368, 0.00728311,\n",
              "        0.00604236, 0.00773986, 0.00655651, 0.00964248, 0.00580588,\n",
              "        0.00417085, 0.01442078, 0.00827979, 0.00960429, 0.00610315,\n",
              "        0.01412415, 0.01112493, 0.01616321, 0.01279166, 0.01329369,\n",
              "        0.00988232, 0.00871006, 0.0070354 , 0.00920124, 0.00974145,\n",
              "        0.00986918, 0.01091626, 0.01195622, 0.01041657, 0.00977146,\n",
              "        0.01350529, 0.01079238, 0.01439314, 0.0169257 , 0.00714194,\n",
              "        0.0093009 , 0.00962608, 0.00403208, 0.00981569, 0.00817893,\n",
              "        0.01243171, 0.00439019, 0.01031141, 0.00784699, 0.00999886,\n",
              "        0.00837655, 0.00750848, 0.00992826, 0.00792219, 0.00521967,\n",
              "        0.0118692 , 0.01108149, 0.01275198, 0.00862548, 0.01247092,\n",
              "        0.01372891, 0.01243675, 0.0104552 , 0.01877163, 0.01596552,\n",
              "        0.00622901, 0.00910422, 0.01409832, 0.00464687, 0.01774443,\n",
              "        0.01319488, 0.00893783, 0.01644854, 0.01225533, 0.01272715,\n",
              "        0.00883022, 0.01278533, 0.01329748, 0.00600914, 0.00974106,\n",
              "        0.00808271, 0.00665632, 0.00584448, 0.0090307 , 0.00652296,\n",
              "        0.00901115, 0.01118521, 0.00677469, 0.0106358 , 0.0093402 ,\n",
              "        0.0076409 , 0.00788863, 0.00804106, 0.00925881, 0.00963047,\n",
              "        0.00853674, 0.01040145, 0.00561389, 0.01311937, 0.0106131 ,\n",
              "        0.00967771, 0.01096853, 0.01157245, 0.01244069, 0.01237119,\n",
              "        0.00997691, 0.01619231, 0.0134241 , 0.00424367, 0.01662795,\n",
              "        0.01614573, 0.00667812, 0.00480849, 0.00297566, 0.00756232,\n",
              "        0.00911684, 0.00969288, 0.00941232, 0.0068343 , 0.01149104,\n",
              "        0.00823859, 0.01002258, 0.00935267, 0.00820521, 0.00826688,\n",
              "        0.0107747 , 0.00612542, 0.01389015, 0.01453717, 0.00815022,\n",
              "        0.00841814, 0.01096149, 0.00832371, 0.00899823, 0.01199855,\n",
              "        0.00561663, 0.01082972, 0.01265747, 0.01054199, 0.01033991,\n",
              "        0.01029118, 0.01502521, 0.01333096, 0.01112298, 0.01301164,\n",
              "        0.01375829, 0.01032642, 0.00681739, 0.00804605, 0.00749389,\n",
              "        0.00839123, 0.0087417 , 0.00865153, 0.00659958, 0.01076578,\n",
              "        0.00617716, 0.00428837, 0.00605411, 0.01195086, 0.00974013,\n",
              "        0.00992354, 0.01206583, 0.0104701 , 0.00754038, 0.00987069,\n",
              "        0.01115541, 0.00789632, 0.00625435, 0.01339355, 0.01066943,\n",
              "        0.01203945, 0.00895844, 0.01056801, 0.01165218, 0.00883425,\n",
              "        0.01328678, 0.00768712, 0.01682898, 0.01178038, 0.01339491,\n",
              "        0.00931594, 0.01160449, 0.01263045, 0.00824488, 0.00513301,\n",
              "        0.01022619, 0.00602048, 0.00892669, 0.00446826, 0.00557559,\n",
              "        0.0062568 , 0.00337407, 0.00819055, 0.00848702, 0.00742313,\n",
              "        0.00658715, 0.01097295, 0.0056966 , 0.01178132, 0.00352805,\n",
              "        0.01082685, 0.01080404, 0.01310634, 0.01180166, 0.00838168,\n",
              "        0.00825774, 0.00890911, 0.01064942, 0.01216107, 0.00742489,\n",
              "        0.00994034, 0.00996096, 0.01197339, 0.0121915 , 0.00843265,\n",
              "        0.00970442, 0.00991964, 0.01137365, 0.01056867]),\n",
              " 'rank_test_score': array([ 50,   6, 124,  36,  47,  74,  73, 161, 160, 112, 146, 102, 217,\n",
              "         49, 196, 235, 104, 181, 304, 301, 291, 191,  81, 175, 253, 166,\n",
              "        230, 284, 212, 153, 276, 142, 263, 315, 307, 240,  46,   2,  15,\n",
              "         17,  43, 105, 118, 196, 226, 102,  96,  87, 280, 177, 196, 300,\n",
              "        134, 130, 272, 259, 205,  90, 230, 245, 271, 162, 171, 316, 312,\n",
              "        309, 323, 215, 275, 195,  55, 322, 141,  42,   3,  89, 165,  86,\n",
              "        238, 282,  63, 117, 228,  66, 201,  94, 310, 279, 121, 123, 244,\n",
              "        299, 126, 256, 297, 178, 100, 127, 188, 183, 243, 217, 267, 180,\n",
              "        153,  61, 113,  59,   9,  12,  33,  47, 227, 174,  24,  53, 285,\n",
              "        172,  43,  41,  39,  97, 155, 133, 115, 239, 209, 249,  54, 131,\n",
              "        190, 285, 183, 209, 311, 306, 152, 302, 232, 305, 202, 266, 324,\n",
              "        257,  13, 136,  14, 146,   8, 138,  50,  68, 127, 144, 247, 162,\n",
              "         78, 113,  79, 164,  37,  76, 150, 186, 207, 258, 289, 194, 192,\n",
              "        293,  90, 172, 189, 253, 222, 235, 158, 296, 261, 298,  21,  80,\n",
              "         30,  81, 155, 187, 110, 106, 135, 109, 268, 193,  45, 270,  20,\n",
              "         95,  31, 183, 293, 291, 242, 321, 248, 167, 119, 314, 318, 196,\n",
              "        317,  98, 240, 203, 132, 288, 214, 264,  27,  29,  52,  84,  18,\n",
              "         66,  70,  10,  24, 216, 246, 137,  38, 262, 287,  40, 149, 289,\n",
              "        127,  88,  35, 181, 169, 224,  65, 232, 265, 168, 229, 274, 319,\n",
              "        255, 252, 144, 307, 313,  60,   7,  22,  11, 101, 111,  69,  34,\n",
              "         56, 139, 176,  99,  26,  16, 122, 120,  81, 209, 205, 213,  70,\n",
              "        260, 220, 223, 281, 143, 151, 148, 179, 295, 250, 155, 251, 268,\n",
              "        204, 276,  32,   1,  92,  57,   5,  70,  19,   4,  93,  23, 140,\n",
              "         58,  75,  27,  84,  62, 272, 207, 283,  77, 107, 125, 219, 169,\n",
              "        108,  64, 116, 196, 303, 220, 237, 278, 225, 320, 158, 232],\n",
              "       dtype=int32),\n",
              " 'split0_train_score': array([0.95973154, 0.94736842, 0.94736842, 0.94666196, 0.99293536,\n",
              "        0.98763688, 0.98481102, 0.98339809, 1.        , 0.9989403 ,\n",
              "        0.99823384, 0.99717414, 0.98269163, 0.9823384 , 0.98198516,\n",
              "        0.97668668, 0.99964677, 0.9989403 , 0.99752738, 0.99505475,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.99717414,\n",
              "        0.99364182, 0.99222889, 0.99081597, 1.        , 1.        ,\n",
              "        0.99964677, 0.99964677, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.95478629, 0.95231367, 0.94984105, 0.94312964,\n",
              "        0.99081597, 0.98728365, 0.98375132, 0.98057224, 1.        ,\n",
              "        0.99964677, 0.99823384, 0.99717414, 0.98551748, 0.97986577,\n",
              "        0.97951254, 0.97633345, 0.99929354, 0.9989403 , 0.99682091,\n",
              "        0.99540798, 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.99576122, 0.99540798, 0.99293536, 0.99222889, 1.        ,\n",
              "        1.        , 1.        , 0.9989403 , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.95655245, 0.95054751, 0.94842812,\n",
              "        0.94842812, 0.99081597, 0.98516425, 0.9823384 , 0.97986577,\n",
              "        0.9989403 , 0.99929354, 0.99788061, 0.99576122, 0.97986577,\n",
              "        0.98163193, 0.97774638, 0.97562699, 0.99717414, 0.99646768,\n",
              "        0.99540798, 0.99434829, 1.        , 1.        , 0.99964677,\n",
              "        0.99964677, 0.99364182, 0.99258213, 0.99152243, 0.98940304,\n",
              "        0.99964677, 0.99964677, 0.99929354, 0.9989403 , 1.        ,\n",
              "        1.        , 1.        , 0.99964677, 0.96503002, 0.96043801,\n",
              "        0.95584599, 0.95302013, 0.99328859, 0.99046273, 0.98869657,\n",
              "        0.98481102, 1.        , 0.99964677, 0.99823384, 0.99717414,\n",
              "        0.99152243, 0.98551748, 0.98410456, 0.98092547, 1.        ,\n",
              "        0.99929354, 0.99929354, 0.99823384, 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.9989403 , 0.99752738, 0.99646768,\n",
              "        0.99364182, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.95973154,\n",
              "        0.95690569, 0.95973154, 0.95337337, 0.99222889, 0.99046273,\n",
              "        0.98693041, 0.98551748, 1.        , 0.99964677, 0.9989403 ,\n",
              "        0.99717414, 0.98834334, 0.98657718, 0.98269163, 0.980219  ,\n",
              "        1.        , 0.99964677, 0.99964677, 0.99823384, 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.99823384, 0.99682091,\n",
              "        0.99470152, 0.99364182, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.96008478, 0.95902508, 0.95407983, 0.9526669 , 0.99081597,\n",
              "        0.99187566, 0.98799011, 0.98375132, 1.        , 0.99858707,\n",
              "        0.99823384, 0.99717414, 0.98763688, 0.98551748, 0.98198516,\n",
              "        0.980219  , 0.9989403 , 0.99823384, 0.99823384, 0.99505475,\n",
              "        1.        , 1.        , 1.        , 0.99929354, 0.99576122,\n",
              "        0.99470152, 0.99505475, 0.99293536, 1.        , 0.99964677,\n",
              "        1.        , 0.9989403 , 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.96503002, 0.96538326, 0.96185094, 0.9537266 ,\n",
              "        0.99682091, 0.99152243, 0.98940304, 0.98516425, 1.        ,\n",
              "        0.99929354, 0.99858707, 0.99717414, 0.99081597, 0.99258213,\n",
              "        0.98834334, 0.98375132, 1.        , 1.        , 0.99929354,\n",
              "        0.99929354, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.99858707, 0.99788061, 0.99682091, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.96291063, 0.9625574 , 0.95725892,\n",
              "        0.95761215, 0.99364182, 0.99364182, 0.98940304, 0.98622395,\n",
              "        1.        , 0.99964677, 0.99823384, 0.99788061, 0.9911692 ,\n",
              "        0.99046273, 0.98551748, 0.98304486, 1.        , 1.        ,\n",
              "        0.99964677, 0.9989403 , 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.99964677, 0.99788061, 0.99752738, 0.99540798,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.96432356, 0.9636171 ,\n",
              "        0.96503002, 0.95725892, 0.99328859, 0.99152243, 0.98799011,\n",
              "        0.98516425, 0.99964677, 0.9989403 , 0.99858707, 0.99717414,\n",
              "        0.99046273, 0.98869657, 0.98799011, 0.98551748, 0.99929354,\n",
              "        0.99929354, 0.99858707, 0.99717414, 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99858707, 0.99717414, 0.99752738,\n",
              "        0.99505475, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        ]),\n",
              " 'split1_train_score': array([0.95407983, 0.9526669 , 0.94842812, 0.9438361 , 0.98940304,\n",
              "        0.98445779, 0.98198516, 0.98163193, 1.        , 0.99964677,\n",
              "        0.99576122, 0.99540798, 0.98481102, 0.97986577, 0.97915931,\n",
              "        0.97527375, 0.99964677, 0.99788061, 0.99788061, 0.99328859,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.99682091,\n",
              "        0.99399505, 0.9911692 , 0.99081597, 1.        , 1.        ,\n",
              "        1.        , 0.99929354, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.95443306, 0.95054751, 0.94807489, 0.94630872,\n",
              "        0.98940304, 0.98657718, 0.98198516, 0.97739315, 0.99964677,\n",
              "        0.99929354, 0.99646768, 0.99364182, 0.98269163, 0.98092547,\n",
              "        0.97492052, 0.97598022, 0.99964677, 0.99788061, 0.99752738,\n",
              "        0.99505475, 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.99505475, 0.99434829, 0.99046273, 0.99187566, 1.        ,\n",
              "        1.        , 1.        , 0.99964677, 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.95619922, 0.9448958 , 0.94807489,\n",
              "        0.94030378, 0.98693041, 0.98445779, 0.97951254, 0.97633345,\n",
              "        0.99823384, 0.99788061, 0.99576122, 0.99328859, 0.98269163,\n",
              "        0.97986577, 0.97703992, 0.9713882 , 0.99858707, 0.99823384,\n",
              "        0.99682091, 0.99399505, 1.        , 0.99964677, 1.        ,\n",
              "        0.99929354, 0.99328859, 0.99293536, 0.99187566, 0.98799011,\n",
              "        0.99964677, 0.99964677, 0.99964677, 0.99823384, 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.95655245, 0.95443306,\n",
              "        0.95125397, 0.95019428, 0.99187566, 0.98693041, 0.98551748,\n",
              "        0.98339809, 1.        , 0.99964677, 0.99788061, 0.99611445,\n",
              "        0.98904981, 0.98516425, 0.98057224, 0.9812787 , 1.        ,\n",
              "        0.99964677, 1.        , 0.99858707, 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99788061, 0.99434829, 0.99505475,\n",
              "        0.99434829, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.95937831,\n",
              "        0.95513953, 0.94842812, 0.94984105, 0.99328859, 0.98834334,\n",
              "        0.98587072, 0.9823384 , 1.        , 0.9989403 , 0.99788061,\n",
              "        0.99646768, 0.98975627, 0.98410456, 0.98375132, 0.97951254,\n",
              "        1.        , 0.99964677, 0.99788061, 0.99752738, 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.99788061, 0.99505475,\n",
              "        0.99328859, 0.99222889, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.95725892, 0.95619922, 0.95160721, 0.94842812, 0.99152243,\n",
              "        0.98834334, 0.98551748, 0.98163193, 0.9989403 , 0.99929354,\n",
              "        0.99682091, 0.99540798, 0.98799011, 0.98410456, 0.98304486,\n",
              "        0.98163193, 0.99964677, 0.99858707, 0.99646768, 0.99858707,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.99611445,\n",
              "        0.99399505, 0.99187566, 0.99540798, 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.96114447, 0.9614977 , 0.95690569, 0.95549276,\n",
              "        0.99328859, 0.99222889, 0.98975627, 0.98304486, 1.        ,\n",
              "        0.99929354, 0.99964677, 0.99823384, 0.98869657, 0.98834334,\n",
              "        0.98657718, 0.98481102, 1.        , 0.99964677, 0.99964677,\n",
              "        0.99858707, 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.99823384, 0.99823384, 0.99717414, 0.99682091, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.95973154, 0.95761215, 0.95867185,\n",
              "        0.95584599, 0.99434829, 0.99081597, 0.98975627, 0.98834334,\n",
              "        0.99964677, 1.        , 0.99929354, 0.99823384, 0.9901095 ,\n",
              "        0.99046273, 0.98728365, 0.98339809, 1.        , 0.99964677,\n",
              "        0.99964677, 0.99788061, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.9989403 , 0.99823384, 0.99823384, 0.99540798,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.96114447, 0.96008478,\n",
              "        0.95761215, 0.95690569, 0.99222889, 0.99434829, 0.98834334,\n",
              "        0.98587072, 0.99929354, 0.99964677, 0.99964677, 0.99646768,\n",
              "        0.99046273, 0.98657718, 0.98516425, 0.98375132, 0.99964677,\n",
              "        0.99929354, 0.99788061, 0.99788061, 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99505475, 0.99752738, 0.99576122,\n",
              "        0.99364182, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        ]),\n",
              " 'split2_train_score': array([0.95584599, 0.94948781, 0.94913458, 0.94101024, 0.99258213,\n",
              "        0.98657718, 0.98516425, 0.97986577, 1.        , 0.99929354,\n",
              "        0.99646768, 0.99364182, 0.98587072, 0.98304486, 0.97456729,\n",
              "        0.97703992, 0.9989403 , 0.99788061, 0.99576122, 0.99682091,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.99682091,\n",
              "        0.99470152, 0.99328859, 0.99152243, 1.        , 1.        ,\n",
              "        1.        , 0.99929354, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.95337337, 0.95196044, 0.94595549, 0.94101024,\n",
              "        0.98975627, 0.98904981, 0.98163193, 0.97774638, 0.99929354,\n",
              "        0.99964677, 0.99611445, 0.99470152, 0.98728365, 0.98445779,\n",
              "        0.97845284, 0.97598022, 0.9989403 , 0.99823384, 0.99682091,\n",
              "        0.99505475, 1.        , 1.        , 1.        , 0.99964677,\n",
              "        0.99576122, 0.99470152, 0.99258213, 0.9901095 , 1.        ,\n",
              "        1.        , 0.99964677, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.95584599, 0.94913458, 0.9537266 ,\n",
              "        0.94524903, 0.98940304, 0.98657718, 0.98375132, 0.97845284,\n",
              "        0.99858707, 0.99752738, 0.99611445, 0.99293536, 0.98481102,\n",
              "        0.97951254, 0.97703992, 0.97280113, 0.99717414, 0.99682091,\n",
              "        0.99505475, 0.99222889, 1.        , 0.99964677, 0.99929354,\n",
              "        0.99823384, 0.99434829, 0.99399505, 0.99222889, 0.98940304,\n",
              "        0.99929354, 0.99964677, 0.99858707, 0.9989403 , 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.96185094, 0.96008478,\n",
              "        0.94772165, 0.95690569, 0.99222889, 0.99046273, 0.98799011,\n",
              "        0.98375132, 1.        , 0.99929354, 0.99858707, 0.99611445,\n",
              "        0.9911692 , 0.98763688, 0.98375132, 0.98092547, 1.        ,\n",
              "        0.9989403 , 0.99823384, 0.99611445, 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99682091, 0.99717414, 0.99434829,\n",
              "        0.99364182, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.96820911,\n",
              "        0.95513953, 0.95196044, 0.95337337, 0.99470152, 0.98975627,\n",
              "        0.98693041, 0.98339809, 0.99964677, 0.9989403 , 0.99823384,\n",
              "        0.99717414, 0.99081597, 0.98622395, 0.98587072, 0.98163193,\n",
              "        1.        , 0.99929354, 0.99788061, 0.99717414, 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.99682091, 0.99717414,\n",
              "        0.99611445, 0.99399505, 1.        , 1.        , 1.        ,\n",
              "        0.99964677, 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.9614977 , 0.96220417, 0.94984105, 0.94524903, 0.99187566,\n",
              "        0.98869657, 0.98516425, 0.98092547, 0.99823384, 0.99788061,\n",
              "        0.99682091, 0.99540798, 0.98799011, 0.98551748, 0.98163193,\n",
              "        0.97986577, 0.9989403 , 0.99752738, 0.99823384, 0.99646768,\n",
              "        1.        , 1.        , 1.        , 0.99964677, 0.99576122,\n",
              "        0.99540798, 0.99434829, 0.99152243, 1.        , 0.99964677,\n",
              "        0.99929354, 0.99964677, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.97103497, 0.96114447, 0.96185094, 0.95973154,\n",
              "        0.99540798, 0.99081597, 0.98834334, 0.98551748, 1.        ,\n",
              "        0.99964677, 0.9989403 , 0.99858707, 0.99293536, 0.99081597,\n",
              "        0.98834334, 0.98657718, 1.        , 0.99964677, 0.99929354,\n",
              "        0.99823384, 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.99858707, 0.99788061, 0.99823384, 0.99717414, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.97103497, 0.96679619, 0.95937831,\n",
              "        0.95584599, 0.99576122, 0.9911692 , 0.98799011, 0.98693041,\n",
              "        0.99964677, 0.99929354, 0.99858707, 0.99717414, 0.99187566,\n",
              "        0.99222889, 0.98940304, 0.98481102, 0.99964677, 0.99964677,\n",
              "        0.99858707, 0.99823384, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.99929354, 0.99752738, 0.99717414, 0.99682091,\n",
              "        1.        , 1.        , 1.        , 0.99964677, 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.96750265, 0.96644295,\n",
              "        0.9614977 , 0.96114447, 0.99328859, 0.9911692 , 0.98834334,\n",
              "        0.98693041, 0.99929354, 0.9989403 , 0.99858707, 0.99646768,\n",
              "        0.99258213, 0.98940304, 0.98763688, 0.97951254, 0.99929354,\n",
              "        0.9989403 , 0.99788061, 0.99752738, 1.        , 1.        ,\n",
              "        0.99964677, 0.99964677, 0.99788061, 0.99682091, 0.99682091,\n",
              "        0.99540798, 0.99964677, 0.99964677, 0.99964677, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        ]),\n",
              " 'split3_train_score': array([0.95443306, 0.95231367, 0.95125397, 0.94701519, 0.98940304,\n",
              "        0.98693041, 0.98375132, 0.97880608, 1.        , 0.9989403 ,\n",
              "        0.99717414, 0.99364182, 0.98516425, 0.98339809, 0.97845284,\n",
              "        0.97598022, 0.9989403 , 0.99823384, 0.99717414, 0.99646768,\n",
              "        1.        , 1.        , 1.        , 0.99964677, 0.99646768,\n",
              "        0.99540798, 0.99364182, 0.99046273, 1.        , 1.        ,\n",
              "        1.        , 0.99964677, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.95761215, 0.95337337, 0.94913458, 0.94842812,\n",
              "        0.98975627, 0.98516425, 0.98516425, 0.97951254, 1.        ,\n",
              "        0.99858707, 0.99682091, 0.99328859, 0.98198516, 0.98445779,\n",
              "        0.97951254, 0.97386083, 0.99929354, 0.99823384, 0.99752738,\n",
              "        0.99646768, 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.99611445, 0.99470152, 0.99364182, 0.9911692 , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.95796538, 0.94913458, 0.95231367,\n",
              "        0.94948781, 0.98799011, 0.98481102, 0.98304486, 0.980219  ,\n",
              "        0.9989403 , 0.99682091, 0.99505475, 0.99470152, 0.98445779,\n",
              "        0.98057224, 0.97809961, 0.97280113, 0.99717414, 0.99682091,\n",
              "        0.99717414, 0.99364182, 1.        , 1.        , 0.99964677,\n",
              "        0.9989403 , 0.99293536, 0.99470152, 0.99187566, 0.98940304,\n",
              "        0.99964677, 0.99929354, 0.9989403 , 0.99788061, 1.        ,\n",
              "        1.        , 1.        , 0.99964677, 0.96573649, 0.95937831,\n",
              "        0.95584599, 0.95655245, 0.99399505, 0.98799011, 0.98763688,\n",
              "        0.98410456, 1.        , 0.99964677, 0.99858707, 0.99682091,\n",
              "        0.98904981, 0.98834334, 0.98516425, 0.98375132, 1.        ,\n",
              "        0.99964677, 0.9989403 , 0.9989403 , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.9989403 , 0.99611445, 0.99434829,\n",
              "        0.99328859, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.96538326,\n",
              "        0.95937831, 0.96326386, 0.95796538, 0.99258213, 0.99187566,\n",
              "        0.98551748, 0.98339809, 1.        , 0.99964677, 0.99788061,\n",
              "        0.99717414, 0.99187566, 0.98763688, 0.98445779, 0.98269163,\n",
              "        0.99964677, 0.99964677, 0.99858707, 0.99611445, 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.99823384, 0.99752738,\n",
              "        0.99540798, 0.99540798, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.96467679, 0.95761215, 0.95407983, 0.9537266 , 0.99222889,\n",
              "        0.98940304, 0.98763688, 0.98304486, 0.99964677, 0.99964677,\n",
              "        0.99788061, 0.99611445, 0.98904981, 0.98728365, 0.98551748,\n",
              "        0.98304486, 0.99929354, 0.99823384, 0.99788061, 0.99717414,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.99540798,\n",
              "        0.99470152, 0.99364182, 0.99399505, 1.        , 1.        ,\n",
              "        1.        , 0.99964677, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.97032851, 0.9625574 , 0.96397033, 0.95937831,\n",
              "        0.99540798, 0.99187566, 0.9901095 , 0.98799011, 1.        ,\n",
              "        1.        , 0.99964677, 0.99788061, 0.99187566, 0.9901095 ,\n",
              "        0.98657718, 0.98834334, 1.        , 1.        , 0.99929354,\n",
              "        0.99929354, 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.9989403 , 0.99823384, 0.9989403 , 0.99505475, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.96926881, 0.96573649, 0.96714942,\n",
              "        0.95867185, 0.99505475, 0.9911692 , 0.99046273, 0.98657718,\n",
              "        1.        , 1.        , 0.99964677, 0.99682091, 0.99258213,\n",
              "        0.99081597, 0.98975627, 0.98869657, 1.        , 1.        ,\n",
              "        0.99929354, 0.9989403 , 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.99964677, 0.99788061, 0.99823384, 0.99646768,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.96997527, 0.96679619,\n",
              "        0.96538326, 0.96291063, 0.99364182, 0.99293536, 0.98799011,\n",
              "        0.98869657, 1.        , 1.        , 0.99858707, 0.99682091,\n",
              "        0.99152243, 0.98904981, 0.98975627, 0.98728365, 0.99964677,\n",
              "        0.99929354, 0.99929354, 0.99788061, 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.9989403 , 0.99752738, 0.99682091,\n",
              "        0.99434829, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        ]),\n",
              " 'split4_train_score': array([0.95338983, 0.95162429, 0.94844633, 0.94491525, 0.99293785,\n",
              "        0.98905367, 0.98163842, 0.97740113, 1.        , 0.99858757,\n",
              "        0.99752825, 0.99435028, 0.98305085, 0.97881356, 0.97810734,\n",
              "        0.97210452, 0.99964689, 0.99823446, 0.99470339, 0.99399718,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.9950565 ,\n",
              "        0.99258475, 0.99223164, 0.98940678, 1.        , 1.        ,\n",
              "        1.        , 0.99929379, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.95621469, 0.94879944, 0.94950565, 0.94173729,\n",
              "        0.99117232, 0.98446328, 0.9805791 , 0.97881356, 1.        ,\n",
              "        1.        , 0.99646893, 0.99258475, 0.98516949, 0.98305085,\n",
              "        0.98022599, 0.9759887 , 0.99894068, 0.99611582, 0.99682203,\n",
              "        0.9950565 , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.99435028, 0.99293785, 0.99258475, 0.98870056, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.95480226, 0.94844633, 0.94632768,\n",
              "        0.94456215, 0.98764124, 0.98587571, 0.98234463, 0.97669492,\n",
              "        0.99964689, 0.99823446, 0.99611582, 0.99187853, 0.98305085,\n",
              "        0.98234463, 0.97740113, 0.97387006, 0.99752825, 0.99682203,\n",
              "        0.99470339, 0.99329096, 1.        , 0.99964689, 1.        ,\n",
              "        0.99964689, 0.99329096, 0.99187853, 0.98834746, 0.98764124,\n",
              "        0.99964689, 1.        , 1.        , 0.99858757, 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.9615113 , 0.95621469,\n",
              "        0.95586158, 0.95091808, 0.99435028, 0.9904661 , 0.98622881,\n",
              "        0.98340395, 1.        , 0.99964689, 0.99858757, 0.99717514,\n",
              "        0.98905367, 0.9855226 , 0.98587571, 0.97881356, 1.        ,\n",
              "        0.99929379, 0.99894068, 0.9954096 , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99788136, 0.99717514, 0.9954096 ,\n",
              "        0.99187853, 1.        , 1.        , 1.        , 0.99964689,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.96221751,\n",
              "        0.95868644, 0.95480226, 0.95233051, 0.99364407, 0.99152542,\n",
              "        0.98764124, 0.9809322 , 1.        , 1.        , 0.99752825,\n",
              "        0.99611582, 0.99081921, 0.98905367, 0.98340395, 0.98128531,\n",
              "        1.        , 0.99929379, 0.99858757, 0.99823446, 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.99717514, 0.99611582,\n",
              "        0.99470339, 0.99223164, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.96468927, 0.96009887, 0.95127119, 0.94632768, 0.99293785,\n",
              "        0.98905367, 0.98516949, 0.9809322 , 0.99964689, 0.99858757,\n",
              "        0.99823446, 0.99646893, 0.98411017, 0.98481638, 0.9855226 ,\n",
              "        0.98269774, 0.99929379, 0.99858757, 0.99717514, 0.9954096 ,\n",
              "        1.        , 1.        , 1.        , 0.99964689, 0.99435028,\n",
              "        0.99399718, 0.99223164, 0.99081921, 1.        , 0.99964689,\n",
              "        0.99964689, 0.99929379, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.96610169, 0.96504237, 0.96257062, 0.95974576,\n",
              "        0.9950565 , 0.99364407, 0.98975989, 0.98870056, 1.        ,\n",
              "        1.        , 0.99894068, 0.99788136, 0.9904661 , 0.99011299,\n",
              "        0.98799435, 0.98446328, 1.        , 0.99964689, 0.99964689,\n",
              "        0.99823446, 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.99929379, 0.99611582, 0.99717514, 0.99435028, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.96786723, 0.96468927, 0.95621469,\n",
              "        0.95833333, 0.99576271, 0.99187853, 0.98940678, 0.98658192,\n",
              "        1.        , 0.99964689, 0.99858757, 0.99682203, 0.99364407,\n",
              "        0.98870056, 0.98870056, 0.98693503, 1.        , 1.        ,\n",
              "        0.99964689, 0.99752825, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.99929379, 0.99717514, 0.99576271, 0.99470339,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.96716102, 0.96433616,\n",
              "        0.95798023, 0.96045198, 0.99364407, 0.99011299, 0.99011299,\n",
              "        0.98870056, 0.99964689, 0.99964689, 0.99858757, 0.99682203,\n",
              "        0.98975989, 0.99187853, 0.98481638, 0.9855226 , 0.99964689,\n",
              "        0.99929379, 0.99858757, 0.99752825, 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99894068, 0.99611582, 0.99646893,\n",
              "        0.9950565 , 0.99964689, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        ]),\n",
              " 'mean_train_score': array([0.95549605, 0.95069222, 0.94892628, 0.94468775, 0.99145228,\n",
              "        0.98693119, 0.98347004, 0.9802206 , 1.        , 0.9990817 ,\n",
              "        0.99703303, 0.99484321, 0.98431769, 0.98149214, 0.97845439,\n",
              "        0.97541702, 0.99936421, 0.99823396, 0.99660935, 0.99512582,\n",
              "        1.        , 1.        , 1.        , 0.99992935, 0.99646803,\n",
              "        0.99406623, 0.99251203, 0.99060478, 1.        , 1.        ,\n",
              "        0.99992935, 0.99943488, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.95528391, 0.95139888, 0.94850233, 0.9441228 ,\n",
              "        0.99018077, 0.98650763, 0.98262235, 0.97880757, 0.99978806,\n",
              "        0.99943483, 0.99682116, 0.99427816, 0.98452948, 0.98255153,\n",
              "        0.97852489, 0.97562868, 0.99922296, 0.99788088, 0.99710372,\n",
              "        0.99540833, 1.        , 1.        , 1.        , 0.99992935,\n",
              "        0.99540838, 0.99441943, 0.99244136, 0.99081676, 1.        ,\n",
              "        1.        , 0.99992935, 0.99971741, 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.95627306, 0.94843176, 0.94977419,\n",
              "        0.94560618, 0.98855615, 0.98537719, 0.98219835, 0.9783132 ,\n",
              "        0.99886968, 0.99795138, 0.99618537, 0.99371304, 0.98297541,\n",
              "        0.98078542, 0.97746539, 0.9732975 , 0.99752755, 0.99703308,\n",
              "        0.99583224, 0.993501  , 1.        , 0.99978809, 0.99971741,\n",
              "        0.99915227, 0.993501  , 0.99321852, 0.99117002, 0.98876809,\n",
              "        0.99957615, 0.99964677, 0.99929354, 0.99851653, 1.        ,\n",
              "        1.        , 1.        , 0.99985871, 0.96213624, 0.95810977,\n",
              "        0.95330584, 0.95351813, 0.9931477 , 0.98926242, 0.98721397,\n",
              "        0.98389379, 1.        , 0.99957615, 0.99837523, 0.99667982,\n",
              "        0.98996898, 0.98643691, 0.98389362, 0.9811389 , 1.        ,\n",
              "        0.99936423, 0.99908167, 0.99745705, 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.9980927 , 0.99646788, 0.99512572,\n",
              "        0.99335981, 1.        , 1.        , 1.        , 0.99992938,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.96298395,\n",
              "        0.9570499 , 0.95563724, 0.95337673, 0.99328904, 0.99039269,\n",
              "        0.98657805, 0.98311685, 0.99992935, 0.99943483, 0.99809272,\n",
              "        0.99682119, 0.99032209, 0.98671925, 0.98403508, 0.98106808,\n",
              "        0.99992935, 0.99950552, 0.99851653, 0.99745685, 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.99766887, 0.9965386 ,\n",
              "        0.99484319, 0.99350108, 1.        , 1.        , 1.        ,\n",
              "        0.99992935, 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.96164149, 0.9590279 , 0.95217582, 0.94927967, 0.99187616,\n",
              "        0.98947446, 0.98629564, 0.98205716, 0.99929356, 0.99879911,\n",
              "        0.99759815, 0.9961147 , 0.98735541, 0.98544791, 0.98354041,\n",
              "        0.98149186, 0.99922294, 0.99823394, 0.99759822, 0.99653865,\n",
              "        1.        , 1.        , 1.        , 0.99971744, 0.99547903,\n",
              "        0.99456065, 0.99343043, 0.99293601, 1.        , 0.99978809,\n",
              "        0.99978809, 0.99950552, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.96672793, 0.96312504, 0.9614297 , 0.957615  ,\n",
              "        0.99519639, 0.9920174 , 0.98947441, 0.98608345, 1.        ,\n",
              "        0.99964677, 0.99915232, 0.9979514 , 0.99095793, 0.99039279,\n",
              "        0.98756708, 0.98558923, 1.        , 0.99978809, 0.99943485,\n",
              "        0.99872849, 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.999011  , 0.99781024, 0.99788081, 0.9960442 , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.96616264, 0.9634783 , 0.95973464,\n",
              "        0.95726186, 0.99491376, 0.99173494, 0.98940379, 0.98693136,\n",
              "        0.99985871, 0.99971744, 0.99886976, 0.99738631, 0.99187611,\n",
              "        0.99053418, 0.9881322 , 0.98537712, 0.99992935, 0.99985871,\n",
              "        0.99936421, 0.99830466, 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.99936423, 0.99773951, 0.99738638, 0.99576159,\n",
              "        1.        , 1.        , 1.        , 0.99992935, 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.96602139, 0.96425543,\n",
              "        0.96150067, 0.95973434, 0.99321839, 0.99201765, 0.98855598,\n",
              "        0.9870725 , 0.99957615, 0.99943485, 0.99879911, 0.99675049,\n",
              "        0.99095798, 0.98912103, 0.98707278, 0.98431752, 0.9995055 ,\n",
              "        0.99922294, 0.99844588, 0.9975982 , 1.        , 1.        ,\n",
              "        0.99992935, 0.99992935, 0.99788068, 0.99703312, 0.99667987,\n",
              "        0.99470187, 0.99985873, 0.99992935, 0.99992935, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        ]),\n",
              " 'std_train_score': array([0.00226423, 0.00199477, 0.0012936 , 0.00217327, 0.0016782 ,\n",
              "        0.00149973, 0.00143579, 0.00210545, 0.        , 0.00036009,\n",
              "        0.00085373, 0.00133281, 0.00123458, 0.00182097, 0.00237458,\n",
              "        0.00176387, 0.00034612, 0.00038695, 0.00119414, 0.00136589,\n",
              "        0.        , 0.        , 0.        , 0.00014129, 0.00074028,\n",
              "        0.00095748, 0.00087652, 0.00069089, 0.        , 0.        ,\n",
              "        0.00014129, 0.00017301, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00147708, 0.00158321, 0.00140482, 0.00281706,\n",
              "        0.00068584, 0.00161578, 0.00163081, 0.00116084, 0.00028259,\n",
              "        0.00047915, 0.00074083, 0.00160111, 0.00194023, 0.0018641 ,\n",
              "        0.00188898, 0.00089429, 0.00026425, 0.00094731, 0.00034591,\n",
              "        0.000547  , 0.        , 0.        , 0.        , 0.00014129,\n",
              "        0.00063121, 0.00081689, 0.00106212, 0.00128204, 0.        ,\n",
              "        0.        , 0.00014129, 0.00041194, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00102889, 0.00189566, 0.00278023,\n",
              "        0.00323615, 0.00138741, 0.00076154, 0.00144103, 0.00158747,\n",
              "        0.00046866, 0.00081783, 0.00093187, 0.00136547, 0.0017506 ,\n",
              "        0.00106388, 0.00041167, 0.00140659, 0.00054722, 0.0006158 ,\n",
              "        0.00098356, 0.00072721, 0.        , 0.00017303, 0.00026433,\n",
              "        0.00052869, 0.00047894, 0.00100827, 0.00142885, 0.00078543,\n",
              "        0.00014131, 0.0002234 , 0.00049955, 0.00041195, 0.        ,\n",
              "        0.        , 0.        , 0.00017305, 0.00325535, 0.00236812,\n",
              "        0.00331149, 0.00278348, 0.00096399, 0.00150913, 0.00116858,\n",
              "        0.00052758, 0.        , 0.00014131, 0.00028266, 0.00047935,\n",
              "        0.00112972, 0.00129425, 0.00182425, 0.00157115, 0.        ,\n",
              "        0.00026432, 0.00057392, 0.00141951, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00079296, 0.00116096, 0.0007868 ,\n",
              "        0.00081675, 0.        , 0.        , 0.        , 0.00014124,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00338305,\n",
              "        0.00175611, 0.00531256, 0.00263254, 0.00086542, 0.00127217,\n",
              "        0.00077509, 0.00150332, 0.00014129, 0.00042388, 0.00047894,\n",
              "        0.00044637, 0.00119501, 0.00163669, 0.00107999, 0.0011083 ,\n",
              "        0.00014129, 0.00017299, 0.0006475 , 0.00078681, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00057376, 0.00087657,\n",
              "        0.00093717, 0.00119416, 0.        , 0.        , 0.        ,\n",
              "        0.00014129, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00283383, 0.00206114, 0.00166393, 0.00337443, 0.00070721,\n",
              "        0.0012516 , 0.00125091, 0.00114654, 0.00063189, 0.00061585,\n",
              "        0.00064761, 0.00067034, 0.00169041, 0.0010567 , 0.00168194,\n",
              "        0.00127671, 0.00026435, 0.00038704, 0.00068482, 0.00127135,\n",
              "        0.        , 0.        , 0.        , 0.00026433, 0.00060698,\n",
              "        0.00052822, 0.0012149 , 0.00165598, 0.        , 0.00017303,\n",
              "        0.00028257, 0.0003602 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00363221, 0.00177024, 0.00239073, 0.00252003,\n",
              "        0.0011303 , 0.00093801, 0.00060806, 0.00204367, 0.        ,\n",
              "        0.00031594, 0.00042384, 0.00046859, 0.00142325, 0.00136609,\n",
              "        0.00081823, 0.00166207, 0.        , 0.00017303, 0.00017308,\n",
              "        0.00047902, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00060775, 0.00087617, 0.00067   , 0.00112532, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00420067, 0.00325066, 0.00386664,\n",
              "        0.00120567, 0.00082418, 0.00101405, 0.00080549, 0.0007405 ,\n",
              "        0.00017305, 0.00026433, 0.00051909, 0.00057371, 0.00120372,\n",
              "        0.00112462, 0.00155772, 0.00215046, 0.00014129, 0.00017305,\n",
              "        0.00041195, 0.00056493, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00026432, 0.00035991, 0.00090968, 0.00077338,\n",
              "        0.        , 0.        , 0.        , 0.00014129, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00302632, 0.00241035,\n",
              "        0.00331798, 0.00231177, 0.00051951, 0.00147424, 0.00079437,\n",
              "        0.00144181, 0.00026434, 0.00042389, 0.00042383, 0.0002644 ,\n",
              "        0.00098817, 0.0016935 , 0.00184903, 0.00264947, 0.00017307,\n",
              "        0.00014132, 0.0005287 , 0.00026429, 0.        , 0.        ,\n",
              "        0.00014129, 0.00014129, 0.00146501, 0.00052819, 0.00057384,\n",
              "        0.00063208, 0.00017302, 0.00014129, 0.00014129, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        ])}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grid_search.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGJVjFwB8j5c",
        "outputId": "839598a0-e1f4-45ec-c71b-3cdf3c9f9137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(colsample_bytree=0.7, gamma=0.2, learning_rate=0.2, max_depth=5,\n",
              "              objective='multi:softprob')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grid_search.best_score_\n",
        "# #cross validation training score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RbHQBkv8oWQ",
        "outputId": "52498f6d-bf09-4de5-af12-3e0ff8786e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7880756598662286"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best_xgb = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "DArhxJy88qQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_xgb.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty_QhP_U8ugY",
        "outputId": "705333e1-ea4d-406f-9894-2e2521b61eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(colsample_bytree=0.7, gamma=0.2, learning_rate=0.2, max_depth=5,\n",
              "              objective='multi:softprob')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# filename = 'finalized_model_XGB.sav'\n",
        "# pickle.dump(best_xgb, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "2WM_g3cl8yTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_y = best_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "9EruenEB86dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "# accuracy = accuracy_score(y_test,pred_y)"
      ],
      "metadata": {
        "id": "hqiCWo2a8_Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "# #test_accuracy"
      ],
      "metadata": {
        "id": "RInDaR909G0T",
        "outputId": "88d8c7a6-496d-460c-ef37-c555470e0494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7593220338983051"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HX2OsYti9JYW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}